{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-03-20T15:50:53.971574Z",
          "iopub.status.busy": "2024-03-20T15:50:53.970357Z",
          "iopub.status.idle": "2024-03-20T15:51:22.748600Z",
          "shell.execute_reply": "2024-03-20T15:51:22.746792Z",
          "shell.execute_reply.started": "2024-03-20T15:50:53.971531Z"
        },
        "id": "J7ToVm-jHRl2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoTokenizer\n",
        "import torch.nn as nn\n",
        "from transformers import AutoConfig, AutoModel\n",
        "import torch.utils.checkpoint\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "from sklearn import metrics\n",
        "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcYqGX78HRl4"
      },
      "source": [
        "# Import and clean datas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-03-20T15:51:22.751824Z",
          "iopub.status.busy": "2024-03-20T15:51:22.751035Z",
          "iopub.status.idle": "2024-03-20T15:51:23.274316Z",
          "shell.execute_reply": "2024-03-20T15:51:23.272698Z",
          "shell.execute_reply.started": "2024-03-20T15:51:22.751787Z"
        },
        "id": "JLtxQ_IlHRl5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"../datas/train_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Md4nnFp3HRl6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def remove_newlines(df):\n",
        "    df = df.replace(\"\\n\", '', regex=True)\n",
        "    return df\n",
        "train_df = remove_newlines(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "-sgjThJTHRl6",
        "outputId": "995a2d7d-511e-424b-cee1-7a9b9bc7bfde",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>filename</th>\n",
              "      <th>texte</th>\n",
              "      <th>sexe</th>\n",
              "      <th>date_accident</th>\n",
              "      <th>date_consolidation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Agen_100515.txt</td>\n",
              "      <td>Le : 12/11/2019  Cour d’appel d’Agen  chambre ...</td>\n",
              "      <td>homme</td>\n",
              "      <td>1991-04-09</td>\n",
              "      <td>n.c.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Agen_1100752.txt</td>\n",
              "      <td>Le : 12/11/2019  Cour d’appel d’Agen  chambre ...</td>\n",
              "      <td>homme</td>\n",
              "      <td>2005-06-10</td>\n",
              "      <td>2010-01-19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Agen_1613.txt</td>\n",
              "      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n",
              "      <td>femme</td>\n",
              "      <td>1997-09-26</td>\n",
              "      <td>n.c.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Agen_2118.txt</td>\n",
              "      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n",
              "      <td>femme</td>\n",
              "      <td>1982-08-07</td>\n",
              "      <td>1982-11-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Agen_21229.txt</td>\n",
              "      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n",
              "      <td>homme</td>\n",
              "      <td>1996-11-26</td>\n",
              "      <td>n.c.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID          filename                                              texte  \\\n",
              "0   0   Agen_100515.txt  Le : 12/11/2019  Cour d’appel d’Agen  chambre ...   \n",
              "1   1  Agen_1100752.txt  Le : 12/11/2019  Cour d’appel d’Agen  chambre ...   \n",
              "2   2     Agen_1613.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n",
              "3   3     Agen_2118.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n",
              "4   4    Agen_21229.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n",
              "\n",
              "    sexe date_accident date_consolidation  \n",
              "0  homme    1991-04-09               n.c.  \n",
              "1  homme    2005-06-10         2010-01-19  \n",
              "2  femme    1997-09-26               n.c.  \n",
              "3  femme    1982-08-07         1982-11-07  \n",
              "4  homme    1996-11-26               n.c.  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95E66Uk_HRl6"
      },
      "source": [
        "# Only keep the sex column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZwjQBkgKHRl6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train = train_df.drop([\"date_accident\", \"date_consolidation\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH0GL0xlHRl6",
        "outputId": "52acdf3a-c5f1-4cb9-b140-d69f28e4c0e8",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/SamuelLP/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = stopwords.words('french')\n",
        "train['texte'] = train[\"texte\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pmIX_gq8HRl6",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train = train.drop([\"ID\", \"filename\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eNchdtQcHRl7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train['text_id'] = np.arange(len(train))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewOW06rOHRl7"
      },
      "source": [
        "# Let's create our dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "5Drc2nLXHRl7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class JuridiqueDataset(Dataset):\n",
        "    def __init__(self,\n",
        "                 df,\n",
        "                 tokenizer,\n",
        "                 args\n",
        "                ):\n",
        "        # args is a dict, a nice way to share the global arguments (even accross multiple files)\n",
        "        self.args = args\n",
        "        self.tokenizer = tokenizer\n",
        "        self.df = df\n",
        "\n",
        "    def make_one_item(self,idx):\n",
        "        # this function should encode (tokenize) a given text\n",
        "        text_id = self.df.iloc[idx].text_id\n",
        "        text = self.df.iloc[idx].texte\n",
        "        sexe = self.df.iloc[idx].sexe\n",
        "        tokenizer_encoding = self.tokenizer(text, max_length=512)\n",
        "        outputs = dict(**tokenizer_encoding)\n",
        "\n",
        "        outputs['text_id'] = text_id\n",
        "        outputs['sexe'] = sexe\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self,idx):\n",
        "        return self.make_one_item(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "MEhcS6KTHRl7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "model_name = \"almanach/camembert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "cBL1gnO1HRl7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import random\n",
        "args = {}\n",
        "ds = JuridiqueDataset(train,tokenizer,args)\n",
        "idx = random.choice(range(len(ds)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-tkb-eVHRl8",
        "outputId": "a8d5ec62-f75e-4e4a-d505-dfd8d856c7b4",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<s>', '▁Le', '▁:', '▁12', '/11/', '2019', '▁Cour', '▁d', '’', 'appel', '▁Saint', '-', 'Denis', '▁Réunion', '▁chambre', '▁civile', '▁Audi', 'ence', '▁publique', '▁6', '▁mars', '▁2015', '▁N', '°', '▁', 'RG', ':', '▁13', '/01', '3', '66', '▁In', 'firm', 'e', '▁décision', '▁déf', 'érée', '▁toutes', '▁dispositions', ',', '▁l', '’', 'égard', '▁toutes', '▁parties', '▁recours', '▁REP', 'UB', 'L', 'IQUE', '▁FRANC', 'A', 'ISE', '▁AU', '▁', 'NOM', '▁DU', '▁PE', 'UP', 'LE', '▁FRANC', 'AIS', '▁C', 'OUR', '▁D', '’', 'APP', 'EL', '▁DE', '▁SAINT', '-', 'DEN', 'IS', '▁A', 'RR', '<unk>', 'T', '▁DU', '▁06', '▁MAR', 'S', '▁2015', '▁Chambre', '▁civile', '▁T', 'GI', '▁A', 'RR', '<unk>', 'T', '▁No', '15', '/', '▁P', 'B', '▁R', '.', '▁G', '▁:', '▁13', '/', '▁01', '3', '66', '▁X', '...', '▁C', '/', '▁Association', '▁G', 'ROU', 'P', 'EMENT', '▁SPORT', 'IF', '▁DE', '▁LA', '▁J', 'EU', 'NES', 'SE', '▁Organ', 'isme', '▁C', 'AIS', 'SE', '▁GE', 'NER', 'ALE', '▁DE', '▁SEC', 'UR', 'ITE', '▁SO', 'CI', 'ALE', '▁DE', '▁LA', '▁RÉ', 'UN', 'ION', '▁Compagnie', '▁d', '’', 'assurance', 's', '▁', 'AZ', 'UR', '▁ASS', 'UR', 'ANCE', 'S', '▁', 'RG', '▁1', 'ERE', '▁IN', 'ST', 'ANCE', '▁:', '▁11', '/', '▁0', '28', '88', '▁Appel', '▁d', '’', 'une', '▁décision', '▁rendue', '▁TR', 'IB', 'UN', 'AL', '▁DE', '▁GRAND', 'E', '▁IN', 'ST', 'ANCE', '▁DE', '▁SAINT', '▁DE', 'NIS', '▁(', 'RÉ', 'UN', 'ION', ')', '▁date', '▁22', '▁MAI', '▁2013', '▁', 'rg', '▁no', '▁11', '/', '▁0', '28', '88', '▁suivant', '▁déclaration', '▁d', '’', 'appel', '▁date', '▁09', '▁J', 'U', 'ILLE', 'T', '▁2013', '▁APP', 'EL', 'ANT', '▁:', '▁Monsieur', '▁Jean', '▁Ulrich', '▁X', '...', '▁...', '▁9', '74', '40', '▁SAINT', '▁', 'ANDR', 'É', '▁Représentant', '▁:', '▁Me', '▁Fernand', 'e', '▁AN', 'IL', 'HA', '▁l', '’', 'Association', '▁AN', 'IL', 'HA', '▁F', 'ERN', 'AND', 'E', '▁ET', '▁MA', 'ILL', 'OT', '▁J', 'UL', 'IEN', ',', '▁avocat', '▁barre', 'au', '▁SAINT', '-', 'DEN', 'IS', '-', 'DE', '-', 'LA', '-', 'RÉ', 'UN', 'ION', '▁aide', '▁juridiction', 'nelle', '▁totale', '▁numéro', '▁2013', '/', '▁48', '24', '▁19', '/', '▁09', '/', '▁2013', '▁accordée', '▁bureau', '▁d', '’', 'aide', '▁juridiction', 'nelle', '▁Saint', '-', 'Denis', '▁', 'INT', 'IM', 'É', 'ES', '▁:', '▁G', 'ROU', 'P', 'EMENT', '▁SPORT', 'IF', '▁DE', '▁LA', '▁J', 'EU', 'NES', 'SE', '▁(', 'association', ')', '▁prise', '▁personne', '▁représentant', '▁légal', '▁exercice', ',', '▁domicilié', '▁', 'ès', '▁qualités', '▁droit', '▁audit', '▁siège', '▁4', '68', '▁rue', '▁B', 'lard', '▁9', '74', '40', '▁SAINT', '▁', 'ANDR', 'É', '▁C', 'AIS', 'SE', '▁G', 'É', 'N', 'ÉR', 'ALE', '▁DE', '▁S', 'É', 'C', 'UR', 'ITÉ', '▁SO', 'CI', 'ALE', '▁DE', '▁LA', '▁RÉ', 'UN', 'ION', '▁prise', '▁personne', '▁directeur', '▁exercice', '▁4', '▁boulevard', '▁Dor', 'et', '▁97', '400', '▁SAINT', '▁DE', 'NIS', '▁Re', 'présent', 'ée', '▁Me', '▁Philippe', '▁B', 'ARRE', '▁S', 'EL', 'ARL', '▁P', 'HL', 'IP', 'PE', '▁B', 'ARRE', ',', '▁avocat', '▁barre', 'au', '▁SAINT', '-', 'DEN', 'IS', '-', 'DE', '-', 'LA', '-', 'RÉ', 'UN', 'ION', '▁Compagnie', '▁d', '’', 'assurance', 's', '▁', 'AZ', 'UR', '▁ASS', 'UR', 'ANCE', 'S', '▁prise', '▁personne', '▁représentant', '▁légal', '▁exercice', ',', '▁domicilié', '▁', 'ès', '▁qualités', '▁droit', '▁audit', '▁siège', '▁07', '▁avenue', '▁Marcel', '▁Proust', '▁2', '89', '32', '▁CHAR', 'TRE', 'S', '▁Re', 'présent', 'ée', '▁Me', '▁Frédérique', '▁F', 'AY', 'ETTE', ',', '▁avocat', '▁barre', 'au', '▁SAINT', '-', 'DEN', 'IS', '-', 'DE', '-', 'LA', '-', 'RÉ', 'UN', 'ION', '▁C', 'LO', 'TURE', '▁LE', '▁:', '▁29', '/', '▁07', '/', '▁2014', '▁DÉ', 'BAT', 'S', '▁:', '▁En', '▁application', '▁dispositions', '▁l', '’', 'article', '▁7', '85', '▁Code', '▁procédure', '▁civile', ',', '▁l', '’', 'affaire', '▁a', '▁débattu', 'e', '▁l', '’', 'audience', '▁publique', '▁06', '▁février', '▁2015', '▁devant', '▁cour', '▁composée', '</s>']\n"
          ]
        }
      ],
      "source": [
        "print(tokenizer.convert_ids_to_tokens(ds[idx]['input_ids']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3yR9VKDHRl8"
      },
      "source": [
        "# Now, we create our DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "qD5q6ioaHRl8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class CustomCollator():\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        output = dict()\n",
        "        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n",
        "        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n",
        "        output[\"sexe\"] = [sample[\"sexe\"] for sample in batch]\n",
        "        output[\"text_id\"] = [sample[\"text_id\"] for sample in batch]\n",
        "\n",
        "\n",
        "        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n",
        "\n",
        "        # add padding\n",
        "        if self.tokenizer.padding_side == \"right\":\n",
        "            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n",
        "            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n",
        "\n",
        "        else:\n",
        "\n",
        "            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n",
        "            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n",
        "\n",
        "        # convert to tensors\n",
        "        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n",
        "        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n",
        "\n",
        "        sexe_to_int = {\"homme\": 0,\n",
        "                       \"femme\": 1,\n",
        "                       \"n.c.\": -1}\n",
        "        output[\"sexe\"] = torch.tensor([sexe_to_int[item] for item in output[\"sexe\"]], dtype=torch.long)\n",
        "        output[\"text_id\"] = torch.tensor(output[\"text_id\"], dtype=torch.long)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Ut4-SCNYHRl8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "collator_function = CustomCollator(tokenizer)\n",
        "my_dataset = JuridiqueDataset(train,tokenizer,args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "7vOQqz7VHRl8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_loader = DataLoader(my_dataset,drop_last = False,num_workers=0,pin_memory=False,shuffle=False,\n",
        "                              batch_size = 2,collate_fn = collator_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFz--OMGHRl8",
        "outputId": "539b4b5e-1da4-48f1-ee12-a0c54dc0355d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/385 [00:00<?, ?it/s]\n"
          ]
        }
      ],
      "source": [
        "for batch in tqdm(data_loader):\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6zh8esAHRl8",
        "outputId": "56614774-a1b5-4c8b-a777-ef141907a9f2",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([2, 512]), torch.Size([2]), torch.Size([2, 512]))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['input_ids'].shape,batch['sexe'].shape,batch['attention_mask'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7WGocqUHRl8",
        "outputId": "2c3c839a-f50e-4857-ee2d-7c64d27bda49",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
              "        [1, 1, 1,  ..., 1, 1, 1]])"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch['attention_mask']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## We create our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "v54YSXK_HRl8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class MyBertModel(nn.Module):\n",
        "    def __init__(self, model_name=\"almanach/camembert-base\", num_labels=2):\n",
        "        super().__init__()\n",
        "        self.config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)\n",
        "        self.backbone = AutoModel.from_pretrained(model_name)\n",
        "        self.fc = nn.Linear(self.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, batch):\n",
        "        inputs = {k: v for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n",
        "        outputs = self.backbone(**inputs)\n",
        "        x = outputs.last_hidden_state[:, 0, :]\n",
        "        x = self.fc(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "DSNpfnkdHRl8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train_one_step(batch,model,criterion):\n",
        "    \"\"\"\n",
        "    Complete this function which should return the loss generate on the bacth data\n",
        "    \"\"\"\n",
        "    # convert bacth data to same device as model\n",
        "    device  = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    batch = batch_to_device(batch,device)\n",
        "    # one step forward with the bacth\n",
        "    pred = model(batch)\n",
        "\n",
        "    # compute loss\n",
        "    loss = criterion(pred.squeeze(),batch['sexe'].float().squeeze(-1))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "JkHymGSPHRl9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "def train_one_epoch(epoch_number,data_loader,model,criterion,optimzer,lr_scheduler):\n",
        "    losses = []\n",
        "    model.train()\n",
        "    start_time = time.time()\n",
        "    pbar = tqdm(data_loader)\n",
        "    for batch in pbar:\n",
        "        loss = train_one_step(batch,model,criterion)\n",
        "        pbar.set_postfix({\"loss\":loss.item()})\n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimzer.step()\n",
        "        lr_scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    lr = scheduler.get_lr()[0]\n",
        "    elapsed_time = time.time() - start_time\n",
        "    loss_ = np.mean(losses)\n",
        "    print(f\"Epoch {epoch_number + 1} :  lr={lr:.6f} t={elapsed_time:.0f}s loss : {loss_:.5f}\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "R1wrL3LQHRl9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def inference(valid_loader, model):\n",
        "    predictions = []\n",
        "    model.eval()\n",
        "\n",
        "    device = next(model.parameters()).device\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(valid_loader):\n",
        "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
        "            pred = model(batch).sigmoid().squeeze()\n",
        "\n",
        "            if pred.dim() == 0:\n",
        "                pred = pred.unsqueeze(0)\n",
        "\n",
        "            predictions.append(pred.detach().cpu().numpy())\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "\n",
        "    df_predict = pd.DataFrame({\"sexe_pred\": predictions.tolist()})\n",
        "    return df_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "z8ZBJWv3HRl9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def batch_to_device(batch, device):\n",
        "    \"\"\"Moves only batch tensors to the specified device.\"\"\"\n",
        "    batch_dict = {}\n",
        "    for key in batch:\n",
        "        if isinstance(batch[key], torch.Tensor):\n",
        "            batch_dict[key] = batch[key].to(device)\n",
        "        else:\n",
        "            batch_dict[key] = batch[key]\n",
        "    return batch_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05O8wksrHRl9",
        "outputId": "73bdc7d7-a67c-467f-93c2-74bf9f9ed005",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MyBertModel(\n",
              "  (backbone): CamembertModel(\n",
              "    (embeddings): CamembertEmbeddings(\n",
              "      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): CamembertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x CamembertLayer(\n",
              "          (attention): CamembertAttention(\n",
              "            (self): CamembertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): CamembertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): CamembertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): CamembertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): CamembertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Define your model\n",
        "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = MyBertModel(model_name=model_name,num_labels=1)\n",
        "net.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "-8WYT2zYHRl9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define an optimzer\n",
        "\n",
        "optimizer = optim.AdamW(net.parameters(),lr = 4e-6 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "B5AZ4FoFHRl9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Define a scheduller for your model training\n",
        "from transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 10\n",
        "warmup_steps = 0.04 * (len(train)//BATCH_SIZE)\n",
        "training_steps = EPOCHS * (len(train)// (BATCH_SIZE))\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, training_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DRGoZJEHRl9",
        "outputId": "0be2c239-9570-48d0-c1cf-d9903360de37",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3.84, 960)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "warmup_steps,training_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KF-5BINHRl9",
        "outputId": "ecfb79db-6e99-4610-d2c6-b4b25dfd1295",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:22<00:00,  4.66it/s, loss=0.284]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:271: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 :  lr=0.000003 t=83s loss : 0.58452\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:24<00:00,  4.53it/s, loss=0.309]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 :  lr=0.000000 t=85s loss : 0.57482\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:25<00:00,  4.48it/s, loss=0.307]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 :  lr=0.000000 t=86s loss : 0.57042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:26<00:00,  4.46it/s, loss=0.299]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 :  lr=0.000003 t=86s loss : 0.57314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:26<00:00,  4.44it/s, loss=0.288]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 :  lr=0.000004 t=87s loss : 0.57232\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:27<00:00,  4.42it/s, loss=0.184]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 :  lr=0.000003 t=87s loss : 0.47023\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:26<00:00,  4.43it/s, loss=0.171]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 :  lr=0.000000 t=87s loss : 0.32552\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:26<00:00,  4.43it/s, loss=0.168]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 :  lr=0.000000 t=87s loss : 0.29475\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:26<00:00,  4.43it/s, loss=0.164]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 :  lr=0.000003 t=87s loss : 0.28901\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 385/385 [01:26<00:00,  4.43it/s, loss=0.137]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 :  lr=0.000004 t=87s loss : 0.25261\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "criterion = nn.BCEWithLogitsLoss().to(device)\n",
        "for epoch_num in range(EPOCHS):\n",
        "    net = train_one_epoch(epoch_num,data_loader,net,criterion,optimizer,scheduler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "NcVWZAGvHRl9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "collator_function = CustomCollator(tokenizer)\n",
        "valid_dataset = JuridiqueDataset(train,tokenizer,args)\n",
        "valid_loader = DataLoader(valid_dataset,drop_last = False,num_workers=0,pin_memory=False,shuffle=False,\n",
        "                              batch_size = 6, collate_fn = collator_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6DwyUstHRl9",
        "outputId": "634eaf37-9997-4125-fd76-8e16ff59e907",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 129/129 [00:37<00:00,  3.44it/s]\n"
          ]
        }
      ],
      "source": [
        "pred_df = inference(valid_loader,net)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZNlltONHRl9"
      },
      "source": [
        "# Let's predict the sex of the victim!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgwqR1w7HRl-"
      },
      "source": [
        "## We will use a TF-IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxI5j019HRl-",
        "outputId": "e53b9dc1-4aa8-44e1-c370-9ae35880a7b5",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:408: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n",
            "  warnings.warn(\n",
            "/var/folders/cs/hh3_26_57sx7l8sdk574zbdh0000gn/T/ipykernel_23574/3468037645.py:8: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  train[\"sexe\"] = train[\"sexe\"].replace({'homme':0, \"femme\":1, \"n.c.\": -1})\n"
          ]
        }
      ],
      "source": [
        "X = train[[\"texte\", 'text_id']]\n",
        "\n",
        "vect = TfidfVectorizer(\n",
        "  max_features=5000,\n",
        "  stop_words=list(fr_stop), binary=True)\n",
        "\n",
        "X = vect.fit_transform(train['texte'])\n",
        "train[\"sexe\"] = train[\"sexe\"].replace({'homme':0, \"femme\":1, \"n.c.\": -1})\n",
        "y = train['sexe']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = LogisticRegression(random_state=42).fit(X, y)\n",
        "\n",
        "preds = clf.predict((X_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYDoSxZ7HRl-"
      },
      "source": [
        "# Now, we compute our metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsm_MGh6HRl-",
        "outputId": "d26d70f3-b72f-46ae-e337-52e6be90ed78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "accuracy: 0.9155844155844156\n",
            "f1: 0.8854363376251788\n"
          ]
        }
      ],
      "source": [
        "print(\"accuracy:\", accuracy_score(y_test, preds))\n",
        "print(\"f1:\", f1_score(y_test, preds, average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 4541802,
          "sourceId": 7765031,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
