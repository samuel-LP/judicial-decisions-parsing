{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from bert_model import BertModel\n",
    "from embedding_model import EmbeddingModel\n",
    "from collator import CustomCollator\n",
    "from dataset import JuridiqueDataset\n",
    "from preprocess import Preprocessing\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "import random\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import our datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../datas/train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(df):\n",
    "    df = df.replace(\"\\n\", '', regex=True)\n",
    "    return df\n",
    "train_df = remove_newlines(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Only keep the sex column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>filename</th>\n",
       "      <th>texte</th>\n",
       "      <th>sexe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Agen_100515.txt</td>\n",
       "      <td>Le : 12/11/2019 Cour d’appel d’Agen chambre so...</td>\n",
       "      <td>homme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Agen_1100752.txt</td>\n",
       "      <td>Le : 12/11/2019 Cour d’appel d’Agen chambre ci...</td>\n",
       "      <td>homme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Agen_1613.txt</td>\n",
       "      <td>Le : 12/11/2019 Cour d’appel d’Agen Audience p...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Agen_2118.txt</td>\n",
       "      <td>Le : 12/11/2019 Cour d’appel d’Agen Audience p...</td>\n",
       "      <td>femme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Agen_21229.txt</td>\n",
       "      <td>Le : 12/11/2019 Cour d’appel d’Agen Audience p...</td>\n",
       "      <td>homme</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID          filename                                              texte  \\\n",
       "0   0   Agen_100515.txt  Le : 12/11/2019 Cour d’appel d’Agen chambre so...   \n",
       "1   1  Agen_1100752.txt  Le : 12/11/2019 Cour d’appel d’Agen chambre ci...   \n",
       "2   2     Agen_1613.txt  Le : 12/11/2019 Cour d’appel d’Agen Audience p...   \n",
       "3   3     Agen_2118.txt  Le : 12/11/2019 Cour d’appel d’Agen Audience p...   \n",
       "4   4    Agen_21229.txt  Le : 12/11/2019 Cour d’appel d’Agen Audience p...   \n",
       "\n",
       "    sexe  \n",
       "0  homme  \n",
       "1  homme  \n",
       "2  femme  \n",
       "3  femme  \n",
       "4  homme  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train_df.drop([\"date_accident\", \"date_consolidation\"], axis=1)\n",
    "preprocess = Preprocessing(train)\n",
    "train = preprocess.remove_stopwords()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop([\"ID\", \"filename\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['text_id'] = np.arange(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's train/test split our datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train, df_test = train_test_split(train, test_size=0.2, random_state=42, stratify=train[\"sexe\"])\n",
    "df_train, df_test = df_train.copy(), df_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's call our created dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"almanach/camembert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {}\n",
    "ds = JuridiqueDataset(train,tokenizer,args)\n",
    "idx = random.choice(range(len(ds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we use our DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator_function = CustomCollator(tokenizer)\n",
    "my_dataset = JuridiqueDataset(train,tokenizer,args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(my_dataset,drop_last = False,num_workers=0,pin_memory=False,shuffle=False,\n",
    "                              batch_size = 2,collate_fn = collator_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in tqdm(data_loader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(batch,model,criterion):\n",
    "    \"\"\"\n",
    "    Complete this function which should return the loss generate on the bacth data\n",
    "    \"\"\"\n",
    "    # convert bacth data to same device as model\n",
    "    device  = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    batch = batch_to_device(batch,device)\n",
    "    # one step forward with the bacth\n",
    "    pred = model(batch)\n",
    "\n",
    "    # compute loss\n",
    "    loss = criterion(pred.squeeze(),batch['sexe'].float().squeeze(-1))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_number,data_loader,model,criterion,optimzer,lr_scheduler):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    pbar = tqdm(data_loader)\n",
    "    for batch in pbar:\n",
    "        loss = train_one_step(batch,model,criterion)\n",
    "        pbar.set_postfix({\"loss\":loss.item()})\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimzer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    lr = scheduler.get_lr()[0]\n",
    "    elapsed_time = time.time() - start_time\n",
    "    loss_ = np.mean(losses)\n",
    "    print(f\"Epoch {epoch_number + 1} :  lr={lr:.6f} t={elapsed_time:.0f}s loss : {loss_:.5f}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(valid_loader, model):\n",
    "    predictions = []\n",
    "    model.eval()\n",
    "\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n",
    "            pred = model(batch).sigmoid().squeeze()\n",
    "\n",
    "            if pred.dim() == 0:\n",
    "                pred = pred.unsqueeze(0)\n",
    "\n",
    "            predictions.append(pred.detach().cpu().numpy())\n",
    "\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "    df_predict = pd.DataFrame({\"sexe_pred\": predictions.tolist()})\n",
    "    return df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_to_device(batch, device):\n",
    "    \"\"\"Moves only batch tensors to the specified device.\"\"\"\n",
    "    batch_dict = {}\n",
    "    for key in batch:\n",
    "        if isinstance(batch[key], torch.Tensor):\n",
    "            batch_dict[key] = batch[key].to(device)\n",
    "        else:\n",
    "            batch_dict[key] = batch[key]\n",
    "    return batch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model\n",
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = BertModel(model_name=model_name,num_labels=1)\n",
    "net.to(device)\n",
    "\n",
    "# Define an optimzer\n",
    "optimizer = optim.AdamW(net.parameters(),lr = 4e-6 )\n",
    "\n",
    "# Define a scheduller for your model training\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 10\n",
    "warmup_steps = 0.04 * (len(train)//BATCH_SIZE)\n",
    "training_steps = EPOCHS * (len(train)// (BATCH_SIZE))\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "for epoch_num in range(EPOCHS):\n",
    "    net = train_one_epoch(epoch_num,data_loader,net,criterion,optimizer,scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collator_function = CustomCollator(tokenizer)\n",
    "valid_dataset = JuridiqueDataset(df_test, tokenizer,args)\n",
    "valid_loader = DataLoader(valid_dataset,drop_last = False,num_workers=0,pin_memory=False,shuffle=False,\n",
    "                              batch_size = 8, collate_fn = collator_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = inference(valid_loader,net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's predict the sex of the victim!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, df):\n",
    "    collator_function = CustomCollator(tokenizer)\n",
    "    valid_dataset = JuridiqueDataset(df, tokenizer, args)\n",
    "    valid_loader = DataLoader(valid_dataset, drop_last=False, num_workers=0, pin_memory=False, shuffle=False,\n",
    "                              batch_size=2, collate_fn=collator_function)\n",
    "    \n",
    "    embed_predictions = []\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            batch = batch_to_device(batch, device)\n",
    "            pred = model(batch)\n",
    "\n",
    "            if pred.dim() == 1:\n",
    "                pred = pred.unsqueeze(0)\n",
    "            pred = pred.detach().cpu().numpy()\n",
    "            embed_predictions.append(pred)\n",
    "    \n",
    "    embeddings = np.concatenate(embed_predictions, axis=0)\n",
    "    df_predict = pd.DataFrame(embeddings)\n",
    "    \n",
    "    return df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = EmbeddingModel(model_name=model_name)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embed_train = get_embeddings(net,df_train)\n",
    "df_embed_test = get_embeddings(net,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_embed_train\n",
    "\n",
    "df_train[\"sexe\"] = df_train[\"sexe\"].replace({\"homme\":1,\n",
    "                      \"femme\":0,\n",
    "                      \"n.c.\":-1})\n",
    "df_test[\"sexe\"] = df_test[\"sexe\"].replace({\"homme\":1,\n",
    "                      \"femme\":0,\n",
    "                      \"n.c.\":-1})\n",
    "y = df_train['sexe']\n",
    "\n",
    "clf = LogisticRegression(multi_class='multinomial', random_state=26).fit(X, y)\n",
    "\n",
    "preds = clf.predict(df_embed_test)\n",
    "\n",
    "y_test = df_test[\"sexe\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now, we compute our metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the embeddings model: 72.0 %\n",
      "f1 of the embeddings model:: 49.0 %\n"
     ]
    }
   ],
   "source": [
    "acc = metrics.accuracy_score(y_test, preds)\n",
    "f1 = metrics.f1_score(y_test, preds, average='macro')\n",
    "\n",
    "print(\"accuracy of the embeddings model:\", 100*round(acc,2),\"%\")\n",
    "print(\"f1 of the embeddings model::\", 100*round(f1,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".nlp_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
