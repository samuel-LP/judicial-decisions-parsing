{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-17T15:39:38.975763Z","iopub.status.busy":"2024-03-17T15:39:38.974697Z","iopub.status.idle":"2024-03-17T15:39:38.980817Z","shell.execute_reply":"2024-03-17T15:39:38.979674Z","shell.execute_reply.started":"2024-03-17T15:39:38.975716Z"},"trusted":true},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:39:38.983163Z","iopub.status.busy":"2024-03-17T15:39:38.982756Z","iopub.status.idle":"2024-03-17T15:40:17.050524Z","shell.execute_reply":"2024-03-17T15:40:17.049293Z","shell.execute_reply.started":"2024-03-17T15:39:38.983122Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/huggingface/transformers\n","  Cloning https://github.com/huggingface/transformers to /private/var/folders/cs/hh3_26_57sx7l8sdk574zbdh0000gn/T/pip-req-build-e691rcke\n","  Running command git clone -q https://github.com/huggingface/transformers /private/var/folders/cs/hh3_26_57sx7l8sdk574zbdh0000gn/T/pip-req-build-e691rcke\n","  Resolved https://github.com/huggingface/transformers to commit a1a7454107e5f005dc55c3f702d96517ad0beca4\n","  Installing build dependencies ... \u001b[?25ldone\n","\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n","\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n","\u001b[?25hRequirement already satisfied: accelerate in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (0.28.0)\n","Requirement already satisfied: bitsandbytes in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (0.42.0)\n","Requirement already satisfied: langchain in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (0.1.12)\n","Requirement already satisfied: sentence-transformers in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (2.5.1)\n","Requirement already satisfied: faiss-cpu in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (1.8.0)\n","Requirement already satisfied: requests in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (2.31.0)\n","Requirement already satisfied: packaging>=20.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (23.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.4.2)\n","Requirement already satisfied: numpy>=1.17 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (1.26.4)\n","Requirement already satisfied: regex!=2019.12.17 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (2023.12.25)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.20.3)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (0.15.2)\n","Requirement already satisfied: pyyaml>=5.1 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (6.0.1)\n","Requirement already satisfied: filelock in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (3.13.1)\n","Requirement already satisfied: tqdm>=4.27 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from transformers==4.39.0.dev0) (4.66.2)\n","Requirement already satisfied: torch>=1.10.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from accelerate) (2.2.1)\n","Requirement already satisfied: psutil in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from accelerate) (5.9.8)\n","Requirement already satisfied: scipy in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from bitsandbytes) (1.12.0)\n","Requirement already satisfied: langchain-community<0.1,>=0.0.28 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (0.0.28)\n","Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (0.1.32)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (0.6.4)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (2.0.28)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Requirement already satisfied: pydantic<3,>=1 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (2.6.2)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (8.2.3)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (1.33)\n","Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (0.1.27)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (3.9.3)\n","Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain) (0.0.1)\n","Requirement already satisfied: Pillow in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from sentence-transformers) (10.2.0)\n","Requirement already satisfied: scikit-learn in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from sentence-transformers) (1.4.1.post1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2024.2.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.9.0)\n","Requirement already satisfied: jsonpointer>=1.9 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n","Requirement already satisfied: anyio<5,>=3 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (4.3.0)\n","Requirement already satisfied: sniffio>=1.1 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n","Requirement already satisfied: idna>=2.8 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (3.6)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n","Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n","Requirement already satisfied: annotated-types>=0.4.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.16.3 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.16.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (2024.2.2)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from requests->transformers==4.39.0.dev0) (2.2.1)\n","Requirement already satisfied: networkx in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: sympy in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: jinja2 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.3.0)\n","Requirement already satisfied: joblib>=1.2.0 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n","Requirement already satisfied: mpmath>=0.19 in /Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","\u001b[33mWARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n","You should consider upgrading via the '/Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"]}],"source":["!pip install git+https://github.com/huggingface/transformers accelerate bitsandbytes langchain sentence-transformers faiss-cpu"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:40:17.052426Z","iopub.status.busy":"2024-03-17T15:40:17.052030Z","iopub.status.idle":"2024-03-17T15:40:17.059837Z","shell.execute_reply":"2024-03-17T15:40:17.058862Z","shell.execute_reply.started":"2024-03-17T15:40:17.052388Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'transformers.utils'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HuggingFacePipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchains\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LLMChain, RetrievalQA, ConversationalRetrievalChain\n","File \u001b[0;32m~/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     47\u001b[0m     logging,\n\u001b[1;32m     48\u001b[0m )\n\u001b[1;32m     51\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mget_logger(\u001b[38;5;18m__name__\u001b[39m)  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n","File \u001b[0;32m~/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdependency_versions_table\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtqdm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyyaml\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.utils'"]}],"source":["import transformers\n","from langchain.llms import HuggingFacePipeline\n","from langchain.chains import LLMChain, RetrievalQA, ConversationalRetrievalChain\n","from langchain.prompts import PromptTemplate\n","from langchain.vectorstores.faiss import FAISS\n","from langchain_core.documents import Document\n","from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n","import pandas as pd\n","from langchain_community.embeddings.openai import OpenAIEmbeddings\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:40:17.063247Z","iopub.status.busy":"2024-03-17T15:40:17.062828Z","iopub.status.idle":"2024-03-17T15:41:19.412857Z","shell.execute_reply":"2024-03-17T15:41:19.410019Z","shell.execute_reply.started":"2024-03-17T15:40:17.063210Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.98s/it]\n"]}],"source":["model = transformers.AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")# , device_map='auto')\n","tokenizer = transformers.AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:41:19.418843Z","iopub.status.busy":"2024-03-17T15:41:19.418399Z","iopub.status.idle":"2024-03-17T15:41:20.107259Z","shell.execute_reply":"2024-03-17T15:41:20.106278Z","shell.execute_reply.started":"2024-03-17T15:41:19.418804Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","\n","train = pd.read_csv(\"../datas/passage_date.csv\")\n","# test = pd.read_csv(\"../datas/test_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:41:20.109023Z","iopub.status.busy":"2024-03-17T15:41:20.108693Z","iopub.status.idle":"2024-03-17T15:41:20.221297Z","shell.execute_reply":"2024-03-17T15:41:20.220381Z","shell.execute_reply.started":"2024-03-17T15:41:20.108993Z"},"trusted":true},"outputs":[],"source":["def remove_newlines(df):\n","    df = df.replace(\"\\n\", '', regex=True)\n","    return df\n","train = remove_newlines(train)\n","# test = remove_newlines(test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:41:20.223407Z","iopub.status.busy":"2024-03-17T15:41:20.223032Z","iopub.status.idle":"2024-03-17T15:41:20.256700Z","shell.execute_reply":"2024-03-17T15:41:20.255464Z","shell.execute_reply.started":"2024-03-17T15:41:20.223378Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>filename</th>\n","      <th>texte</th>\n","      <th>sexe</th>\n","      <th>date_accident</th>\n","      <th>date_consolidation</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Agen_100515.txt</td>\n","      <td>Le : 12/11/2019  Cour d’appel d’Agen  chambre ...</td>\n","      <td>homme</td>\n","      <td>1991-04-09</td>\n","      <td>n.c.</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Agen_1100752.txt</td>\n","      <td>Le : 12/11/2019  Cour d’appel d’Agen  chambre ...</td>\n","      <td>homme</td>\n","      <td>2005-06-10</td>\n","      <td>2010-01-19</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Agen_1613.txt</td>\n","      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n","      <td>femme</td>\n","      <td>1997-09-26</td>\n","      <td>n.c.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Agen_2118.txt</td>\n","      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n","      <td>femme</td>\n","      <td>1982-08-07</td>\n","      <td>1982-11-07</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Agen_21229.txt</td>\n","      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n","      <td>homme</td>\n","      <td>1996-11-26</td>\n","      <td>n.c.</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   ID          filename                                              texte  \\\n","0   0   Agen_100515.txt  Le : 12/11/2019  Cour d’appel d’Agen  chambre ...   \n","1   1  Agen_1100752.txt  Le : 12/11/2019  Cour d’appel d’Agen  chambre ...   \n","2   2     Agen_1613.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n","3   3     Agen_2118.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n","4   4    Agen_21229.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n","\n","    sexe date_accident date_consolidation  \n","0  homme    1991-04-09               n.c.  \n","1  homme    2005-06-10         2010-01-19  \n","2  femme    1997-09-26               n.c.  \n","3  femme    1982-08-07         1982-11-07  \n","4  homme    1996-11-26               n.c.  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:41:20.258595Z","iopub.status.busy":"2024-03-17T15:41:20.258248Z","iopub.status.idle":"2024-03-17T15:41:20.276212Z","shell.execute_reply":"2024-03-17T15:41:20.275338Z","shell.execute_reply.started":"2024-03-17T15:41:20.258565Z"},"trusted":true},"outputs":[],"source":["texte = train[\"texte\"].tolist()"]},{"cell_type":"markdown","metadata":{},"source":["# RAG pipeline"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:41:20.278112Z","iopub.status.busy":"2024-03-17T15:41:20.277684Z","iopub.status.idle":"2024-03-17T15:41:20.299399Z","shell.execute_reply":"2024-03-17T15:41:20.298253Z","shell.execute_reply.started":"2024-03-17T15:41:20.278061Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /Users/SamuelLP/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["import nltk\n","from nltk.tokenize import sent_tokenize\n","\n","nltk.download('punkt') # Décommente cette ligne si 'punkt' n'a pas déjà été téléchargé\n","\n","def preprocess_documents(df_or_series):\n","    pages_content = []\n","    \n","    # Vérifie si l'objet est une Series et le convertit en DataFrame si nécessaire\n","    if isinstance(df_or_series, pd.Series):\n","        df = df_or_series.to_frame().transpose()\n","    else:\n","        df = df_or_series\n","    \n","    for index, row in df.iterrows():\n","        texte = row[\"texte\"]\n","        name = row[\"filename\"]\n","        \n","        # Découpe le texte en phrases\n","        phrases = sent_tokenize(texte)\n","        \n","        for phrase in phrases:\n","            texte_doc = Document(page_content=phrase,\n","                                 metadata={'name': name})\n","            pages_content.append(texte_doc)\n","        \n","    return pages_content"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:41:20.303753Z","iopub.status.busy":"2024-03-17T15:41:20.303420Z","iopub.status.idle":"2024-03-17T15:41:20.326854Z","shell.execute_reply":"2024-03-17T15:41:20.325713Z","shell.execute_reply.started":"2024-03-17T15:41:20.303726Z"},"trusted":true},"outputs":[],"source":["content = preprocess_documents(train.iloc[3,:])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:41:20.328548Z","iopub.status.busy":"2024-03-17T15:41:20.328192Z","iopub.status.idle":"2024-03-17T15:41:22.434181Z","shell.execute_reply":"2024-03-17T15:41:22.433220Z","shell.execute_reply.started":"2024-03-17T15:41:20.328519Z"},"trusted":true},"outputs":[],"source":["embedding_model = SentenceTransformerEmbeddings(model_name='almanach/camembert-base')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-17T15:41:22.436131Z","iopub.status.busy":"2024-03-17T15:41:22.435672Z","iopub.status.idle":"2024-03-17T15:41:24.194183Z","shell.execute_reply":"2024-03-17T15:41:24.192450Z","shell.execute_reply.started":"2024-03-17T15:41:22.436071Z"},"trusted":true},"outputs":[],"source":["faiss_index = FAISS.from_documents(content, embedding_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:41:24.195282Z","iopub.status.idle":"2024-03-17T15:41:24.195800Z","shell.execute_reply":"2024-03-17T15:41:24.195552Z","shell.execute_reply.started":"2024-03-17T15:41:24.195531Z"},"trusted":true},"outputs":[],"source":["retriever = faiss_index.as_retriever(search_kwargs={'k': 6})"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:41:24.198022Z","iopub.status.idle":"2024-03-17T15:41:24.198546Z","shell.execute_reply":"2024-03-17T15:41:24.198310Z","shell.execute_reply.started":"2024-03-17T15:41:24.198289Z"},"trusted":true},"outputs":[],"source":["text_generation_pipeline = transformers.pipeline(\n","    model=model,\n","    tokenizer=tokenizer,\n","    task=\"text-generation\",\n","    temperature=0,\n","    repetition_penalty=1.2,\n","    return_full_text=True,\n","    max_new_tokens=2000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:41:24.200281Z","iopub.status.idle":"2024-03-17T15:41:24.200654Z","shell.execute_reply":"2024-03-17T15:41:24.200489Z","shell.execute_reply.started":"2024-03-17T15:41:24.200472Z"},"trusted":true},"outputs":[],"source":["mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:41:24.202153Z","iopub.status.idle":"2024-03-17T15:41:24.202479Z","shell.execute_reply":"2024-03-17T15:41:24.202331Z","shell.execute_reply.started":"2024-03-17T15:41:24.202317Z"},"trusted":true},"outputs":[],"source":["qa = ConversationalRetrievalChain.from_llm(llm=mistral_llm,\n","                                           retriever=retriever,\n","                                           return_source_documents=True,\n","                                           verbose=False)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:41:24.203558Z","iopub.status.idle":"2024-03-17T15:41:24.203872Z","shell.execute_reply":"2024-03-17T15:41:24.203728Z","shell.execute_reply.started":"2024-03-17T15:41:24.203715Z"},"trusted":true},"outputs":[],"source":["query = \"Quelle est la date de consolidation?\"\n","# queries = [\"Quel est le sexe de la victime?\", \"Quel est la date de l'accident?\", \"Quelle est la date de consolidation?\"]\n","queries = [\"Quelle est la date d'accident?\"]"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:41:24.205394Z","iopub.status.idle":"2024-03-17T15:41:24.205770Z","shell.execute_reply":"2024-03-17T15:41:24.205601Z","shell.execute_reply.started":"2024-03-17T15:41:24.205585Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n","  warn_deprecated(\n","/Users/SamuelLP/Desktop/git/projet_nlp/.nlp_venv/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n","  warnings.warn(\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"]}],"source":["\n","for query in queries :\n","\n","    if query == \"Quel est le sexe de la victime?\":\n","        result = qa({\"question\" : f\"\"\"Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n","    On va te demander les informations suivantes : Sexe de la victime, date de l'accident, date de consolidation.\n","    Le sexe de la victime est toujours contenu dans le document et ne peux prendre que deux valeurs : \"homme\" ou \"femme\".\n","    voici la demande : {query} \"\"\",\n","    \"chat_history\": []})\n","\n","    elif query == \"Quelle est la date de l'accident?\":\n","        result = qa({\"question\" : f\"\"\"Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n","    On va te demander les informations suivantes : Sexe de la victime, date de l'accident, date de consolidation.\n","    La date de l'accident correspond à la date à laquelle l'accident s'est produit. Elle est toujours quelque part dans le document (généralement au début) sauf dans de très rares cas.. Nous attendons une date au format jj/mm/aaaa.\n","    voici la demande : {query} \"\"\",\n","    \"chat_history\": []})\n","\n","    elif query == \"Quelle est la date de consolidation?\":\n","        result = qa({\"question\" : f\"\"\"Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n","    On va te demander les informations suivantes : Sexe de la victime, date de l'accident, date de consolidation.\n","    La date de consolidation est la date à laquelle les blessures de la victime sont devenues stables et ont été déclarées définitives par un médecin. L'information devrait être présente dans la plupart des cas mais parfois elle est soit manquante (tu afficheras la valeur \"n.c.\") soit non applicable (tu afficheras la valeur \"n.a.\") si la blessure n'a pas stabilisé avant le décès de la victime.\n","    voici la demande : {query} \"\"\",\n","    \"chat_history\": []})\n"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:41:24.206882Z","iopub.status.idle":"2024-03-17T15:41:24.207373Z","shell.execute_reply":"2024-03-17T15:41:24.207172Z","shell.execute_reply.started":"2024-03-17T15:41:24.207154Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","- Agen_2118.txt\n","\n","- Agen_2118.txt\n","\n","- Agen_2118.txt\n","\n","- Agen_2118.txt\n","\n","- Agen_2118.txt\n","\n","- Agen_2118.txt\n"]}],"source":["for element in result[\"source_documents\"]:\n","    source = f'\\n- {element.metadata[\"name\"]}'\n","    print(source)"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.status.busy":"2024-03-17T15:41:24.208629Z","iopub.status.idle":"2024-03-17T15:41:24.208975Z","shell.execute_reply":"2024-03-17T15:41:24.208817Z","shell.execute_reply.started":"2024-03-17T15:41:24.208801Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" The information about the victim's gender is not provided in the given texts.\n"]}],"source":["print(result['answer'])"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["'\\n- Agen_2118.txt'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["source"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4610736,"sourceId":7860140,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
