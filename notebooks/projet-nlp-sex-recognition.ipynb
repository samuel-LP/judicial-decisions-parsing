{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-20T15:50:53.971574Z","iopub.status.busy":"2024-03-20T15:50:53.970357Z","iopub.status.idle":"2024-03-20T15:51:22.748600Z","shell.execute_reply":"2024-03-20T15:51:22.746792Z","shell.execute_reply.started":"2024-03-20T15:50:53.971531Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import torch\n","from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\n","import re\n","import nltk\n","from nltk.corpus import stopwords\n","from torch.utils.data import Dataset\n","from transformers import AutoTokenizer\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import f1_score, accuracy_score\n","from sklearn import metrics\n","from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T15:51:22.751824Z","iopub.status.busy":"2024-03-20T15:51:22.751035Z","iopub.status.idle":"2024-03-20T15:51:23.274316Z","shell.execute_reply":"2024-03-20T15:51:23.272698Z","shell.execute_reply.started":"2024-03-20T15:51:22.751787Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv(\"../datas/train_data.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-20T15:51:23.279932Z","iopub.status.busy":"2024-03-20T15:51:23.279138Z","iopub.status.idle":"2024-03-20T15:51:23.306217Z","shell.execute_reply":"2024-03-20T15:51:23.305028Z","shell.execute_reply.started":"2024-03-20T15:51:23.279879Z"},"trusted":true},"outputs":[],"source":["train_df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def remove_newlines(df):\n","    df = df.replace(\"\\n\", '', regex=True)\n","    return df\n","train_df = remove_newlines(train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_df.head()"]},{"cell_type":"markdown","metadata":{},"source":["# For sex"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = train_df.drop([\"date_accident\", \"date_consolidation\"], axis=1)\n","train = train[train.sexe != \"n.c.\"]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["nltk.download('stopwords')\n","stop_words = stopwords.words('french')\n","train['texte'] = train[\"texte\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train = train.drop([\"ID\", \"filename\"], axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train['text_id'] = np.arange(len(train))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class JuridiqueDataset(Dataset):\n","    def __init__(self,\n","                 df,\n","                 tokenizer,\n","                 args\n","                ):\n","        # args is a dict, a nice way to share the global arguments (even accross multiple files)\n","        self.args = args\n","        self.tokenizer = tokenizer\n","        self.df = df\n","        \n","    def make_one_item(self,idx):\n","        # this function should encode (tokenize) a given text \n","        text_id = self.df.iloc[idx].text_id\n","        text = self.df.iloc[idx].texte\n","        sexe = self.df.iloc[idx].sexe\n","        tokenizer_encoding = self.tokenizer(text, max_length=512)\n","        outputs = dict(**tokenizer_encoding)\n","        \n","        outputs['text_id'] = text_id\n","        outputs['sexe'] = sexe\n","        \n","        return outputs\n","    \n","    def __len__(self) -> int:\n","        return len(self.df)\n","    \n","    def __getitem__(self,idx):\n","        return self.make_one_item(idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","model_name = \"almanach/camembert-base\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import random\n","args = {}\n","ds = JuridiqueDataset(train,tokenizer,args)\n","idx = random.choice(range(len(ds)))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(tokenizer.convert_ids_to_tokens(ds[idx]['input_ids']))"]},{"cell_type":"markdown","metadata":{},"source":["# DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["## =============================================================================== ##\n","class CustomCollator():\n","    def __init__(self, tokenizer):\n","        self.tokenizer = tokenizer\n","\n","    def __call__(self, batch):\n","        output = dict()\n","        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n","        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n","        output[\"sexe\"] = [sample[\"sexe\"] for sample in batch]\n","        output[\"text_id\"] = [sample[\"text_id\"] for sample in batch]\n","\n","\n","        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n","\n","        # add padding\n","        if self.tokenizer.padding_side == \"right\":\n","            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n","\n","        else:\n","\n","            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n","            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n","\n","        # convert to tensors\n","        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n","        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n","        \n","        sexe_to_int = {\"homme\": 0, \"femme\": 1}\n","        output[\"sexe\"] = torch.tensor([sexe_to_int[item] for item in output[\"sexe\"]], dtype=torch.long)\n","        # output[\"sexe\"] = torch.tensor(output[\"sexe\"], dtype=torch.long)#.unsqueeze(-1) #mettre float au lieu de long\n","        output[\"text_id\"] = torch.tensor(output[\"text_id\"], dtype=torch.long)\n","        return output\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["collator_function = CustomCollator(tokenizer)\n","my_dataset = JuridiqueDataset(train,tokenizer,args)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data_loader = DataLoader(my_dataset,drop_last = False,num_workers=0,pin_memory=False,shuffle=False,\n","                              batch_size = 2,collate_fn = collator_function)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","for batch in tqdm(data_loader):\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch['input_ids'].shape,batch['sexe'].shape,batch['attention_mask'].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["batch['attention_mask']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import torch.nn as nn\n","from transformers import AutoConfig, AutoModel\n","import torch.utils.checkpoint\n","import torch.nn.functional as F\n","\n","class MyBertModel(nn.Module):\n","    def __init__(self, model_name=\"almanach/camembert-base\", num_labels=2):\n","        super().__init__()\n","        self.config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)        \n","        self.backbone = AutoModel.from_pretrained(model_name)\n","        self.fc = nn.Linear(self.config.hidden_size, num_labels)\n","\n","    def forward(self, batch):\n","        inputs = {k: v for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n","        outputs = self.backbone(**inputs)\n","        x = outputs.last_hidden_state[:, 0, :]\n","        x = self.fc(x)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_one_step(batch,model,criterion):\n","    \"\"\"\n","    Complete this function which should return the loss generate on the bacth data\n","    \"\"\"\n","    # convert bacth data to same device as model\n","    device  = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    batch = batch_to_device(batch,device)\n","    # one step forward with the bacth\n","    pred = model(batch)\n","    \n","    # compute loss \n","    loss = criterion(pred.squeeze(),batch['sexe'].float().squeeze(-1))\n","#     print(loss)\n","    return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_one_epoch(epoch_number,data_loader,model,criterion,optimzer,lr_scheduler):\n","    losses = []\n","    model.train()\n","    start_time = time.time()\n","    pbar = tqdm(data_loader)\n","    for batch in pbar:\n","        loss = train_one_step(batch,model,criterion)\n","        pbar.set_postfix({\"loss\":loss.item()})\n","        losses.append(loss.item())\n","        loss.backward()\n","        optimzer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","    \n","    lr = scheduler.get_lr()[0]\n","    elapsed_time = time.time() - start_time\n","    loss_ = np.mean(losses)\n","    print(f\"Epoch {epoch_number + 1} :  lr={lr:.6f} t={elapsed_time:.0f}s loss : {loss_:.5f}\")\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","def inference(valid_loader, model):\n","    predictions = []\n","    model.eval()  # Met le modèle en mode évaluation.\n","    \n","    device = next(model.parameters()).device\n","    \n","    with torch.no_grad():\n","        for batch in tqdm(valid_loader):\n","            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n","            pred = model(batch).sigmoid().squeeze()\n","            \n","            if pred.dim() == 0:\n","                pred = pred.unsqueeze(0)\n","            \n","            predictions.append(pred.detach().cpu().numpy())\n","    \n","    predictions = np.concatenate(predictions, axis=0)\n","    \n","    df_predict = pd.DataFrame({\"sexe_pred\": predictions.tolist()})\n","    return df_predict"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def batch_to_device(batch, device):\n","    \"\"\"Déplace uniquement les tenseurs du batch vers le dispositif spécifié.\"\"\"\n","    batch_dict = {}\n","    for key in batch:\n","        if isinstance(batch[key], torch.Tensor):\n","            batch_dict[key] = batch[key].to(device)\n","        else:\n","            batch_dict[key] = batch[key]\n","    return batch_dict\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define your model\n","device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","net = MyBertModel(model_name=model_name,num_labels=1)\n","net.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define an optimzer \n","import torch.optim as optim\n","\n","optimizer = optim.AdamW(net.parameters(),lr = 4e-6 )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define a scheduller for your model training\n","from transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\n","\n","BATCH_SIZE = 6\n","EPOCHS = 8\n","warmup_steps = 0.04 * (len(train)//BATCH_SIZE)\n","training_steps = EPOCHS * (len(train)// (BATCH_SIZE))\n","\n","scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, training_steps)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["warmup_steps,training_steps"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import time\n","\n","criterion = nn.BCEWithLogitsLoss().to(device)\n","for epoch_num in range(EPOCHS):\n","    net = train_one_epoch(epoch_num,data_loader,net,criterion,optimizer,scheduler)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["collator_function = CustomCollator(tokenizer)\n","valid_dataset = JuridiqueDataset(train,tokenizer,args)\n","valid_loader = DataLoader(valid_dataset,drop_last = False,num_workers=0,pin_memory=False,shuffle=False,\n","                              batch_size = 6,collate_fn = collator_function)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pred_df = inference(valid_loader,net)"]},{"cell_type":"markdown","metadata":{},"source":["# TF-IDF"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","X = train[[\"texte\", 'text_id']]\n","\n","vect = TfidfVectorizer(\n","  max_features=5000,\n","  stop_words=list(fr_stop), binary=True)\n","\n","X = vect.fit_transform(train['texte'])\n","train[\"sexe\"] = train[\"sexe\"].replace({'homme':0, \"femme\":1})\n","y = train['sexe']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=26)\n","\n","clf = LogisticRegression(random_state=26).fit(X, y)\n","\n","preds = clf.predict((X_test))\n","\n","print(\"f1:\", f1_score(y_test, preds, average='macro'))\n","print(\"accuracy:\", accuracy_score(y_test, preds))\n","fpr, tpr, thresholds = metrics.roc_curve(y_test, preds)\n","print(\"AUC: \", metrics.auc(fpr, tpr))"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4541802,"sourceId":7765031,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
