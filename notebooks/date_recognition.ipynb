{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T07:39:19.846795Z","iopub.status.busy":"2024-03-28T07:39:19.845960Z","iopub.status.idle":"2024-03-28T07:40:15.361413Z","shell.execute_reply":"2024-03-28T07:40:15.360107Z","shell.execute_reply.started":"2024-03-28T07:39:19.846745Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting langchain\n","  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n","Collecting sentence-transformers\n","  Downloading sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n","Collecting faiss-cpu\n","  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n","Collecting langchain-openai\n","  Downloading langchain_openai-0.1.1-py3-none-any.whl.metadata (2.5 kB)\n","Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n","Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\n","Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\n","Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n","Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\n","Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n","Collecting langchain-community<0.1,>=0.0.29 (from langchain)\n","  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n","Collecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n","  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n","Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n","  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\n","Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n","  Downloading langsmith-0.1.36-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\n","Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\n","Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n","Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n","Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.38.2)\n","Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.1)\n","Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.1.2)\n","Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n","Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\n","Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.21.4)\n","Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\n","Collecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n","  Downloading openai-1.14.3-py3-none-any.whl.metadata (20 kB)\n","Collecting tiktoken<1,>=0.5.2 (from langchain-openai)\n","  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n","Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n","Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n","Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (21.3)\n","Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n","Collecting packaging>=20.9 (from huggingface-hub>=0.15.1->sentence-transformers)\n","  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n","Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n","  Downloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m721.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.2.0)\n","Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n","Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n","Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n","Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n","Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.2)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n","Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n","Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n","Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n","Downloading langchain-0.1.13-py3-none-any.whl (810 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading sentence_transformers-2.6.1-py3-none-any.whl (163 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.3/163.3 kB\u001b[0m \u001b[31m820.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m947.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading langchain_openai-0.1.1-py3-none-any.whl (32 kB)\n","Downloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m761.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading langchain_core-0.1.35-py3-none-any.whl (273 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.0/273.0 kB\u001b[0m \u001b[31m954.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n","\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n","Downloading langsmith-0.1.36-py3-none-any.whl (86 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.9/86.9 kB\u001b[0m \u001b[31m760.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading openai-1.14.3-py3-none-any.whl (262 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m880.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m976.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading orjson-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/144.8 kB\u001b[0m \u001b[31m800.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m571.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: packaging, orjson, faiss-cpu, tiktoken, openai, langsmith, langchain-core, sentence-transformers, langchain-text-splitters, langchain-openai, langchain-community, langchain\n","  Attempting uninstall: packaging\n","    Found existing installation: packaging 21.3\n","    Uninstalling packaging-21.3:\n","      Successfully uninstalled packaging-21.3\n","  Attempting uninstall: orjson\n","    Found existing installation: orjson 3.9.10\n","    Uninstalling orjson-3.9.10:\n","      Successfully uninstalled orjson-3.9.10\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","cudf 23.8.0 requires cubinlinker, which is not installed.\n","cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","cudf 23.8.0 requires ptxcompiler, which is not installed.\n","cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n","keras-cv 0.8.2 requires keras-core, which is not installed.\n","keras-nlp 0.8.2 requires keras-core, which is not installed.\n","tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n","apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n","apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n","apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\n","cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\n","cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n","cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","dask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","dask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n","distributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","google-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\n","jupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n","libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\n","osmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\n","raft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\n","spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n","tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\n","ydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed faiss-cpu-1.8.0 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.35 langchain-openai-0.1.1 langchain-text-splitters-0.0.1 langsmith-0.1.36 openai-1.14.3 orjson-3.10.0 packaging-23.2 sentence-transformers-2.6.1 tiktoken-0.6.0\n"]}],"source":["!pip install langchain sentence-transformers faiss-cpu langchain-openai"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-28T07:40:15.363758Z","iopub.status.busy":"2024-03-28T07:40:15.363408Z","iopub.status.idle":"2024-03-28T07:40:40.789335Z","shell.execute_reply":"2024-03-28T07:40:40.788475Z","shell.execute_reply.started":"2024-03-28T07:40:15.363730Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-03-28 07:40:18.685337: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-03-28 07:40:18.685456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-03-28 07:40:18.853666: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import torch\n","\n","from langchain_core.documents import Document\n","from langchain_community.embeddings.openai import OpenAIEmbeddings\n","\n","from langchain_community.vectorstores import FAISS\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnablePassthrough\n","from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n","\n","from langchain_community.embeddings import HuggingFaceEmbeddings\n","from langchain_core.prompts import ChatPromptTemplate\n","\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","from nltk.corpus import stopwords\n","\n","import re\n","from datetime import datetime\n","from tqdm import tqdm\n","\n","import os\n","import getpass\n","\n","from sklearn.metrics import f1_score\n","nltk.download('punkt')\n","stop_words = stopwords.words(\"french\")\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"markdown","metadata":{},"source":["# Import datas"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T07:41:41.830286Z","iopub.status.busy":"2024-03-28T07:41:41.829631Z","iopub.status.idle":"2024-03-28T07:41:42.384898Z","shell.execute_reply":"2024-03-28T07:41:42.383909Z","shell.execute_reply.started":"2024-03-28T07:41:41.830255Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv(\"../datas/psg_date.csv\")\n","train = pd.read_csv(\"../datas/train_data.csv\")\n","\n","data.rename(columns={\"contexte\":\"texte\"}, inplace=True)\n","\n","data['texte'] = data['texte'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n","\n","\n","data[\"date_accident\"] = train[\"date_accident\"]\n","data[\"date_consolidation\"] = train[\"date_consolidation\"]"]},{"cell_type":"markdown","metadata":{},"source":["# Insert your API key"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T07:41:51.454973Z","iopub.status.busy":"2024-03-28T07:41:51.454618Z","iopub.status.idle":"2024-03-28T07:41:51.459819Z","shell.execute_reply":"2024-03-28T07:41:51.458725Z","shell.execute_reply.started":"2024-03-28T07:41:51.454946Z"},"trusted":true},"outputs":[],"source":["os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI key:\")"]},{"cell_type":"markdown","metadata":{},"source":["# Function for preprocess your datas"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T07:43:28.564300Z","iopub.status.busy":"2024-03-28T07:43:28.563565Z","iopub.status.idle":"2024-03-28T07:43:28.572422Z","shell.execute_reply":"2024-03-28T07:43:28.571267Z","shell.execute_reply.started":"2024-03-28T07:43:28.564265Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["def preprocess_documents(df_or_series):\n","    pages_content = []\n","    \n","    if isinstance(df_or_series, pd.Series):\n","        df = df_or_series.to_frame().transpose()\n","    else:\n","        df = df_or_series\n","    \n","    for index, row in df.iterrows():\n","        texte = row[\"texte\"]\n","        name = row[\"filename\"]\n","        \n","        # Découpe le texte en phrases\n","        phrases = sent_tokenize(texte)\n","        \n","        for phrase in phrases:\n","            texte_doc = Document(page_content=phrase,\n","                                 metadata={'name': name})\n","            pages_content.append(texte_doc)\n","        \n","    return pages_content"]},{"cell_type":"markdown","metadata":{},"source":["# After that, we define our retriveal function"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T08:02:30.931099Z","iopub.status.busy":"2024-03-28T08:02:30.930409Z","iopub.status.idle":"2024-03-28T08:02:30.942312Z","shell.execute_reply":"2024-03-28T08:02:30.941394Z","shell.execute_reply.started":"2024-03-28T08:02:30.931063Z"},"trusted":true},"outputs":[],"source":["def retriver(df, query, openai_model, embedding_model_name):\n","    res_date = []\n","\n","    for _, row in tqdm(df.iterrows(), total=df.shape[0]):\n","\n","        texte = row[\"texte\"]\n","        filename = row[\"filename\"]\n","\n","        content = preprocess_documents(pd.Series({\"texte\": texte, \"filename\": filename}))\n","\n","        if openai_model != None:\n","            model = ChatOpenAI(model=openai_model, temperature=0.2)\n","\n","        else :\n","            model = ChatOpenAI(temperature=0.2)\n","\n","        if embedding_model_name == None:\n","            embedding_model = OpenAIEmbeddings()\n","            faiss_index = FAISS.from_documents(content, embedding_model)\n","\n","        else:\n","            embedding_model = HuggingFaceEmbeddings(model_name=embedding_model_name)\n","            faiss_index = FAISS.from_documents(content, embedding_model)\n","        \n","        retriever = faiss_index.as_retriever(search_kwargs={'k': 7}, search_type=\"mmr\")\n","\n","        if query == \"what is the date of accident?\":\n","            template = \"\"\"You are a legal assistant. You will look for information in the following document::\n","            {context}.\n","            You will search for one of the following information :\n","            - the date of the accident : The date of the accident refers to the date on which the accident occurred\n","            You will only return the date with the following format : YYYY-MM-DD. I don't want text around it\n","            The user is going to ask you the following thing: {question}\n","            \"\"\"\n","\n","            prompt = ChatPromptTemplate.from_template(template)\n","\n","            chain = (\n","            {\"context\": retriever, \"question\": RunnablePassthrough()}\n","            | prompt\n","            | model\n","            | StrOutputParser()\n","            )\n","\n","            val = chain.invoke(query)\n","            # print(val)\n","            res_date.append(val)\n","\n","        elif query == \"what is the date of consolidation?\":\n","            template = \"\"\"You are a legal assistant. You will look for information in the following document::\n","            {context}.\n","\n","            You will search for one of the following information :\n","            - the date of consolidation : The consolidation date is the date on which the victim's injuries\n","            became stable and were declared definitive by a doctor.\n","            The information should be present in most cases, but sometimes it is either missing (you will display the value \"n.c.\") or not applicable (you will display the value \"n.a.\") if the injury did not stabilize before the victim's death.\n","\n","            You will return the date with the following format : YYYY-MM-DD. I don't want text around it\n","            If the date of consolidation is missing in the document, you will return the value n.c.\n","            If the injury did not stabilize before the victim's death, you will return the value n.a.\n","\n","            The user is going to ask you the following thing: {question}\n","            \"\"\"\n","\n","            prompt = ChatPromptTemplate.from_template(template)\n","\n","            chain = (\n","            {\"context\": retriever, \"question\": RunnablePassthrough()}\n","            | prompt\n","            | model\n","            | StrOutputParser()\n","            )\n","\n","            val = chain.invoke(query)\n","            res_date.append(val)\n","    return res_date"]},{"cell_type":"markdown","metadata":{},"source":["# We normalize our outputs"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["french_months = {\n","    'janvier': 1, 'février': 2, 'mars': 3, 'avril': 4, 'mai': 5, 'juin': 6,\n","    'juillet': 7, 'août': 8, 'septembre': 9, 'octobre': 10, 'novembre': 11, 'décembre': 12\n","}\n","\n","def extract_and_reformat_date(text):\n","    if 'n.c.' in text:\n","        return \"n.c.\"\n","    elif \"n.a.\" in text: \n","        return 'n.a.'\n","    \n","    date_pattern_ymd = r\"\\d{4}-\\d{2}-\\d{2}\"\n","    date_pattern_dmy = r\"(\\d{1,2}),?\\s([a-zA-Zéû]+)\\s(\\d{4})\"\n","    date_pattern_slash = r\"(\\d{1,2})/(\\d{1,2})/(\\d{4})\"\n","    date_pattern_mdy = r\"([a-zA-Z]+) (\\d{1,2}), (\\d{4})\"\n","    \n","    match_ymd = re.search(date_pattern_ymd, text)\n","    match_dmy = re.search(date_pattern_dmy, text)\n","    match_slash = re.search(date_pattern_slash, text)\n","    match_mdy = re.search(date_pattern_mdy, text)\n","    \n","    if match_ymd:\n","        return match_ymd.group(0)\n","    elif match_dmy:\n","        day, month_name, year = match_dmy.groups()\n","        try:\n","            month_number = datetime.strptime(month_name, \"%B\").month\n","        except ValueError:\n","            month_number = french_months.get(month_name.lower())\n","            if month_number is None:\n","                return None\n","        return f\"{year}-{month_number:02d}-{day.zfill(2)}\"\n","    elif match_slash:\n","        part1, part2, year = match_slash.groups()\n","        day, month = part1, part2  # Assumant le format JJ/MM/AAAA\n","        return f\"{year}-{int(month):02d}-{int(day):02d}\"\n","    elif match_mdy:\n","        month_name, day, year = match_mdy.groups()\n","        try:\n","            month_number = datetime.strptime(month_name, \"%B\").month\n","        except ValueError:\n","            return None  # En cas de mois inconnu en anglais\n","        return f\"{year}-{month_number:02d}-{day.zfill(2)}\"\n","    else:\n","        return None"]},{"cell_type":"markdown","metadata":{},"source":["# Now, we apply our RAG"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["OPENAI_MODEL = \"gpt-3.5-turbo\"\n","EMBEDDING_MODEL_NAME = \"xlm-r-distilroberta-base-paraphrase-v1\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query = \"what is the date of accident?\"\n","\n","res_date_accident = retriver(train, query, OPENAI_MODEL, EMBEDDING_MODEL_NAME)\n","train[\"date_accident_pred\"] = res_date_accident"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["query = \"what is the date of consolidation?\"\n","\n","res_date_consolidation = retriver(train, query, OPENAI_MODEL, EMBEDDING_MODEL_NAME)\n","train[\"date_consolidation_pred\"] = res_date_consolidation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["train['date_accident_pred'] = train['date_accident_pred'].apply(extract_and_reformat_date)\n","train['date_consolidation_pred'] = train['date_consolidation_pred'].apply(extract_and_reformat_date)\n","train = train.fillna(value=np.nan)\n","train = train.fillna(value='n.c.')"]},{"cell_type":"markdown","metadata":{},"source":["# Let's compute our metrics"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy accident: 0.712987012987013\n","Accuracy consolidation: 0.5467532467532468\n"]}],"source":["def compute_accuracy(df, y_true, y_pred):\n","\n","    good_preds = (df[y_true] == df[y_pred]).sum()\n","    lenght = df.shape[0]\n","\n","    accuracy = good_preds / lenght\n","    return accuracy\n","\n","accuracy_accident = compute_accuracy(train, 'date_accident', 'date_accident_pred')\n","accuracy_consolidation = compute_accuracy(train, 'date_consolidation', 'date_consolidation_pred')\n","\n","print(f\"Accuracy accident: {accuracy_accident}\")\n","print(f\"Accuracy consolidation: {accuracy_consolidation}\")"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["F1 accident: 0.8324488248673237\n","F1 consolidation: 0.7069689336691856\n"]}],"source":["def compute_f1(df, y_true, y_pred):\n","\n","    y_t = (df[y_true] == df[y_true]).astype(int)\n","    y_p = (df[y_pred] == df[y_true]).astype(int)\n","\n","    f1 = f1_score(y_t, y_p)\n","\n","    return f1\n","\n","f1_accident = compute_f1(train, 'date_accident', 'date_accident_pred')\n","f1_consolidation = compute_f1(train, 'date_consolidation', 'date_consolidation_pred')\n","\n","print(f\"F1 accident: {f1_accident}\")\n","print(f\"F1 consolidation: {f1_consolidation}\")"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T08:53:06.842404Z","iopub.status.busy":"2024-03-28T08:53:06.842010Z","iopub.status.idle":"2024-03-28T08:53:07.686044Z","shell.execute_reply":"2024-03-28T08:53:07.685042Z","shell.execute_reply.started":"2024-03-28T08:53:06.842371Z"},"trusted":true},"outputs":[],"source":["train.to_csv(\"../datas/preds_rag_openai.csv\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4638972,"sourceId":7899283,"sourceType":"datasetVersion"},{"datasetId":4643865,"sourceId":7905881,"sourceType":"datasetVersion"},{"datasetId":4661053,"sourceId":7930101,"sourceType":"datasetVersion"},{"datasetId":4661360,"sourceId":7930503,"sourceType":"datasetVersion"},{"datasetId":4684728,"sourceId":7963224,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
