{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7899283,"sourceType":"datasetVersion","datasetId":4638972},{"sourceId":7905881,"sourceType":"datasetVersion","datasetId":4643865}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport torch\nimport transformers\nfrom transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-23T15:27:35.925944Z","iopub.execute_input":"2024-03-23T15:27:35.926285Z","iopub.status.idle":"2024-03-23T15:28:00.791872Z","shell.execute_reply.started":"2024-03-23T15:27:35.926255Z","shell.execute_reply":"2024-03-23T15:28:00.790446Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-23 15:27:39.348308: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-23 15:27:39.348429: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-23 15:27:39.514080: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers accelerate bitsandbytes langchain sentence-transformers faiss-cpu\n","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:28:00.794010Z","iopub.execute_input":"2024-03-23T15:28:00.794606Z","iopub.status.idle":"2024-03-23T15:29:03.798178Z","shell.execute_reply.started":"2024-03-23T15:28:00.794578Z","shell.execute_reply":"2024-03-23T15:29:03.797134Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-qp8rpg02\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-qp8rpg02\n  Resolved https://github.com/huggingface/transformers to commit c5f0288bc7d76f65996586f79f69fba8867a0e67\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\nCollecting langchain\n  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\nCollecting sentence-transformers\n  Downloading sentence_transformers-2.6.0-py3-none-any.whl.metadata (11 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-community<0.1,>=0.0.29 (from langchain)\n  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\nCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.31-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (4.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (4.2.0)\nCollecting packaging>=20.0 (from transformers==4.40.0.dev0)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m800.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.1.13-py3-none-any.whl (810 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.6.0-py3-none-any.whl (163 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.1/163.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[?25hDownloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.40.0.dev0-py3-none-any.whl size=8802691 sha256=c3f12cdf5c3d3f61fcd0a953fd7e7be8ea37c514a0ae2de889a785b95f4b9839\n  Stored in directory: /tmp/pip-ephem-wheel-cache-i_ievt9g/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\nSuccessfully built transformers\nInstalling collected packages: packaging, orjson, faiss-cpu, langsmith, bitsandbytes, transformers, langchain-core, sentence-transformers, langchain-text-splitters, langchain-community, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.2\n    Uninstalling transformers-4.38.2:\n      Successfully uninstalled transformers-4.38.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.43.0 faiss-cpu-1.8.0 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 orjson-3.9.15 packaging-23.2 sentence-transformers-2.6.0 transformers-4.40.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.llms import HuggingFacePipeline\nfrom langchain.chains import LLMChain, RetrievalQA, ConversationalRetrievalChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.vectorstores.faiss import FAISS\nfrom langchain_core.documents import Document\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\nimport pandas as pd\nfrom langchain_community.embeddings.openai import OpenAIEmbeddings\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:29:03.799675Z","iopub.execute_input":"2024-03-23T15:29:03.799995Z","iopub.status.idle":"2024-03-23T15:29:04.948769Z","shell.execute_reply.started":"2024-03-23T15:29:03.799965Z","shell.execute_reply":"2024-03-23T15:29:04.947956Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"results_df = pd.read_csv(\"/kaggle/input/dates-dataset/passages_dates.csv\", index_col=[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:29:04.951097Z","iopub.execute_input":"2024-03-23T15:29:04.951395Z","iopub.status.idle":"2024-03-23T15:29:06.311163Z","shell.execute_reply.started":"2024-03-23T15:29:04.951370Z","shell.execute_reply":"2024-03-23T15:29:06.310359Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"results_df.rename(columns={\"contexts\": \"texte\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:29:06.312531Z","iopub.execute_input":"2024-03-23T15:29:06.313243Z","iopub.status.idle":"2024-03-23T15:29:06.578908Z","shell.execute_reply.started":"2024-03-23T15:29:06.313208Z","shell.execute_reply":"2024-03-23T15:29:06.577831Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"results_df","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:29:06.581600Z","iopub.execute_input":"2024-03-23T15:29:06.582139Z","iopub.status.idle":"2024-03-23T15:29:06.623516Z","shell.execute_reply.started":"2024-03-23T15:29:06.582114Z","shell.execute_reply":"2024-03-23T15:29:06.622594Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                  filename                                              texte\n0          Agen_100515.txt  Le 12 11 2019 Cour d appel d Agen chambre soci...\n1         Agen_1100752.txt  Le 12 11 2019 Cour d appel d Agen chambre civi...\n2            Agen_1613.txt  Le 12 11 2019 Cour d appel d Agen Audience pub...\n3            Agen_2118.txt  Le 12 11 2019 Cour d appel d Agen Audience pub...\n4           Agen_21229.txt  Le 12 11 2019 Cour d appel d Agen Audience pub...\n..                     ...                                                ...\n765  Versailles_602516.txt  Le 12 11 2019 Cour d appel de Versailles ct003...\n766  Versailles_605885.txt  Le 12 11 2019 Cour d appel de Versailles ct008...\n767   Versailles_61934.txt  Le 12 11 2019 Cour d appel de Versailles ct008...\n768   Versailles_67325.txt  Le 12 11 2019 Cour d appel de Versailles ct008...\n769  Versailles_903789.txt  Le 12 11 2019 Cour d appel de Versailles 5ème ...\n\n[770 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>texte</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Agen_100515.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen chambre soci...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Agen_1100752.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen chambre civi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Agen_1613.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen Audience pub...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Agen_2118.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen Audience pub...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Agen_21229.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen Audience pub...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>Versailles_602516.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles ct003...</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>Versailles_605885.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles ct008...</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>Versailles_61934.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles ct008...</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>Versailles_67325.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles ct008...</td>\n    </tr>\n    <tr>\n      <th>769</th>\n      <td>Versailles_903789.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles 5ème ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>770 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"results_df = results_df[:2] # juste pour le test","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:29:06.624741Z","iopub.execute_input":"2024-03-23T15:29:06.625026Z","iopub.status.idle":"2024-03-23T15:29:06.629470Z","shell.execute_reply.started":"2024-03-23T15:29:06.625001Z","shell.execute_reply":"2024-03-23T15:29:06.628414Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# RAG","metadata":{}},{"cell_type":"code","source":"model = transformers.AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", device_map='auto')\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")","metadata":{"execution":{"iopub.status.busy":"2024-03-23T15:29:06.630776Z","iopub.execute_input":"2024-03-23T15:29:06.631089Z"},"trusted":true},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1a24e1a17394319a671b0a4e9e116d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0efdc291082f42c6a348b218c1a0add0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"479d736e52b44cde86ad847c4fdf8770"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f9389a5ff8b4acc870bc5312a33e2e5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d847e5ad1384c2ba45d8c12127ae082"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b0a369d532940c696c223cd8371dcc2"}},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download('punkt') # Décommente cette ligne si 'punkt' n'a pas déjà été téléchargé\n\ndef preprocess_documents(df_or_series):\n    pages_content = []\n    \n    # Vérifie si l'objet est une Series et le convertit en DataFrame si nécessaire\n    if isinstance(df_or_series, pd.Series):\n        df = df_or_series.to_frame().transpose()\n    else:\n        df = df_or_series\n    \n    for index, row in df.iterrows():\n        texte = row[\"texte\"]\n        name = row[\"filename\"]\n        \n        # Découpe le texte en phrases\n        phrases = sent_tokenize(texte)\n        \n        for phrase in phrases:\n            texte_doc = Document(page_content=phrase,\n                                 metadata={'name': name})\n            pages_content.append(texte_doc)\n        \n    return pages_content","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"content = preprocess_documents(results_df)\nembedding_model = SentenceTransformerEmbeddings(model_name='multi-qa-distilbert-cos-v1')\nfaiss_index = FAISS.from_documents(content, embedding_model)\nretriever = faiss_index.as_retriever(search_kwargs={'k': 3})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_generation_pipeline = transformers.pipeline(\n    model=model,\n    tokenizer=tokenizer,\n    task=\"text-generation\",\n    temperature=0,\n    repetition_penalty=1.2,\n    return_full_text=True,\n    max_new_tokens=2000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"qa = ConversationalRetrievalChain.from_llm(llm=mistral_llm,\n                                           retriever=retriever,\n                                           return_source_documents=True,\n                                           verbose=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"queries = [\"Quelle est la date de l'accident?\"]\nfor query in queries :\n\n    if query == \"Quelle est la date de l'accident?\":\n        result = qa({\"question\" : f\"\"\"Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n    On va te demander les informations suivantes : Sexe de la victime, date de l'accident, date de consolidation.\n    La date de l'accident correspond à la date à laquelle l'accident s'est produit. Elle est toujours quelque part dans le document (généralement au début) sauf dans de très rares cas.\n    voici la demande : {query} ATTENTION: Tu me renverras la date au format MM-DD-AAAA\n\"\"\",\n    \"chat_history\": []})\n\n    elif query == \"Quelle est la date de consolidation?\":\n        result = qa({\"question\" : f\"\"\"Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n    On va te demander les informations suivantes : Sexe de la victime, date de l'accident, date de consolidation.\n    La date de consolidation est la date à laquelle les blessures de la victime sont devenues stables et ont été déclarées définitives par un médecin. L'information devrait être présente dans la plupart des cas mais parfois elle est soit manquante (tu afficheras la valeur \"n.c.\") soit non applicable (tu afficheras la valeur \"n.a.\") si la blessure n'a pas stabilisé avant le décès de la victime.\n    voici la demande : {query} \"\"\",\n    \"chat_history\": []})\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for element in result[\"source_documents\"]:\n    source = f'\\n- {element.metadata[\"name\"]}'\n    print(source)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(result['answer'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}