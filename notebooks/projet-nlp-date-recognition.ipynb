{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7899283,"sourceType":"datasetVersion","datasetId":4638972},{"sourceId":7905881,"sourceType":"datasetVersion","datasetId":4643865}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport torch\nimport transformers\nfrom transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-21T14:09:16.783801Z","iopub.execute_input":"2024-03-21T14:09:16.784146Z","iopub.status.idle":"2024-03-21T14:09:40.355892Z","shell.execute_reply.started":"2024-03-21T14:09:16.784118Z","shell.execute_reply":"2024-03-21T14:09:40.355040Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-21 14:09:19.995059: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-21 14:09:19.995155: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-21 14:09:20.147172: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install git+https://github.com/huggingface/transformers accelerate bitsandbytes langchain sentence-transformers faiss-cpu\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:09:40.357619Z","iopub.execute_input":"2024-03-21T14:09:40.358183Z","iopub.status.idle":"2024-03-21T14:10:54.547935Z","shell.execute_reply.started":"2024-03-21T14:09:40.358158Z","shell.execute_reply":"2024-03-21T14:10:54.546679Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/huggingface/transformers\n  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-_elzrgqb\n  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-_elzrgqb\n  Resolved https://github.com/huggingface/transformers to commit de627f5a14a777d5cbf21edb78ed67ceb900f8dd\n  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nCollecting bitsandbytes\n  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\nCollecting langchain\n  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\nCollecting sentence-transformers\n  Downloading sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\nCollecting faiss-cpu\n  Downloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.40.0.dev0) (4.66.1)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-community<0.1,>=0.0.29 (from langchain)\n  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\nCollecting langchain-core<0.2.0,>=0.1.33 (from langchain)\n  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.31-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.4)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (9.5.0)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.40.0.dev0) (4.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain) (4.2.0)\nCollecting packaging>=20.0 (from transformers==4.40.0.dev0)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m974.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.40.0.dev0) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\nRequirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.3.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain) (1.2.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nDownloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading langchain-0.1.13-py3-none-any.whl (810 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading sentence_transformers-2.5.1-py3-none-any.whl (156 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faiss_cpu-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.29-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.33-py3-none-any.whl (269 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.31-py3-none-any.whl (71 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m936.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: transformers\n  Building wheel for transformers (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for transformers: filename=transformers-4.40.0.dev0-py3-none-any.whl size=8804843 sha256=562abc9fafce8314555eb42c357fa53b1c7675b202fb933b0b24bc42ab58096e\n  Stored in directory: /tmp/pip-ephem-wheel-cache-vnknoxqt/wheels/c0/14/d6/6c9a5582d2ac191ec0a483be151a4495fe1eb2a6706ca49f1b\nSuccessfully built transformers\nInstalling collected packages: packaging, orjson, faiss-cpu, langsmith, bitsandbytes, transformers, langchain-core, sentence-transformers, langchain-text-splitters, langchain-community, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n  Attempting uninstall: transformers\n    Found existing installation: transformers 4.38.2\n    Uninstalling transformers-4.38.2:\n      Successfully uninstalled transformers-4.38.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.2 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.4.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.3.1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed bitsandbytes-0.43.0 faiss-cpu-1.8.0 langchain-0.1.13 langchain-community-0.0.29 langchain-core-0.1.33 langchain-text-splitters-0.0.1 langsmith-0.1.31 orjson-3.9.15 packaging-23.2 sentence-transformers-2.5.1 transformers-4.40.0.dev0\n","output_type":"stream"}]},{"cell_type":"code","source":"from langchain.llms import HuggingFacePipeline\nfrom langchain.chains import LLMChain, RetrievalQA, ConversationalRetrievalChain\nfrom langchain.prompts import PromptTemplate\nfrom langchain.vectorstores.faiss import FAISS\nfrom langchain_core.documents import Document\nfrom langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\nimport pandas as pd\nfrom langchain_community.embeddings.openai import OpenAIEmbeddings\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:10:54.549660Z","iopub.execute_input":"2024-03-21T14:10:54.550006Z","iopub.status.idle":"2024-03-21T14:10:55.524293Z","shell.execute_reply.started":"2024-03-21T14:10:54.549978Z","shell.execute_reply":"2024-03-21T14:10:55.523343Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/train-datasets/train_data.csv\")\ndef remove_newlines(df):\n    df = df.replace(\"\\n\", '', regex=True)\n    return df\ntrain = remove_newlines(train)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:10:55.526460Z","iopub.execute_input":"2024-03-21T14:10:55.526754Z","iopub.status.idle":"2024-03-21T14:10:56.062723Z","shell.execute_reply.started":"2024-03-21T14:10:55.526730Z","shell.execute_reply":"2024-03-21T14:10:56.061643Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"from transformers import pipeline, AutoTokenizer, AutoModelForTokenClassification\nimport re\n\ndef divide_text_into_batches(text, n_batches):\n    \"\"\"\n    Divise un texte en n_batches parties égales.\n    \"\"\"\n    batch_size = len(text) // n_batches\n    return [text[i:i+batch_size] for i in range(0, len(text), batch_size)]\n\ndef extract_sentences_around_dates(batch, model, tokenizer, context_window):\n    \"\"\"\n    Extrait les dates et environ 50 mots avant et après ces dates dans un batch de texte.\n    \"\"\"\n    ner_pipeline = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n    results = ner_pipeline(batch)\n    dates_and_contexts = []\n\n    for result in results:\n        if result['entity'] == 'B-DATE' or result['entity'] == 'I-DATE':\n            # Identifier le contexte complet de la date dans le batch\n            start, end = result['start'], result['end']\n            pre_context = batch[max(0, start - context_window*6):start]  # Estimation approximative\n            post_context = batch[end:end + context_window*6]\n            \n            # Extraire la phrase complète autour de la date\n            sentence_boundaries = re.search(r'([.!?]\\s+)|([.!?]$)', pre_context[::-1])\n            pre_sentence_boundary = -sentence_boundaries.start(0) if sentence_boundaries else -len(pre_context)\n            sentence_boundaries = re.search(r'([.!?]\\s+)|([.!?]$)', post_context)\n            post_sentence_boundary = sentence_boundaries.end(0) if sentence_boundaries else len(post_context)\n            \n            full_context = pre_context[pre_sentence_boundary:] + batch[start:end] + post_context[:post_sentence_boundary]\n            \n            # Nettoyer et extraire les mots autour de la date pour limiter à environ 50 mots avant et après\n            words_around_date = re.findall(r'\\w+', full_context)\n            date_index = len(re.findall(r'\\w+', pre_context[pre_sentence_boundary:]))\n            start_context = max(0, date_index - context_window)\n            end_context = min(len(words_around_date), date_index + context_window)\n            \n            context_sentence = ' '.join(words_around_date[start_context:end_context])\n            dates_and_contexts.append((batch[start:end], context_sentence))\n\n    return dates_and_contexts\n\ndef extract_dates_with_context_from_long_text(text, model, tokenizer, n_batches, context_window):\n    \"\"\"\n    Gère les textes longs par découpage en batches et extrait les phrases autour des dates identifiées.\n    \"\"\"\n    batches = divide_text_into_batches(text, n_batches)\n    all_dates_and_contexts = []\n\n    for batch in batches:\n        batch_dates_and_contexts = extract_sentences_around_dates(batch, model, tokenizer, context_window)\n        all_dates_and_contexts.extend(batch_dates_and_contexts)\n\n    return all_dates_and_contexts\n\n\nmodel_name = \"Jean-Baptiste/camembert-ner-with-dates\"\nmodel = AutoModelForTokenClassification.from_pretrained(model_name)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\ntext = train[\"texte\"][0]\nN_BATCHES = 15\nCONTEXT = 50\n\ndates_and_contexts = extract_dates_with_context_from_long_text(text, model, tokenizer,\n                                                               N_BATCHES, CONTEXT)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:10:56.064181Z","iopub.execute_input":"2024-03-21T14:10:56.064493Z","iopub.status.idle":"2024-03-21T14:11:03.573623Z","shell.execute_reply.started":"2024-03-21T14:10:56.064467Z","shell.execute_reply":"2024-03-21T14:11:03.572643Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/970 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cee3a31764d742c296e908a81f52495d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa9129b9888242d1a1dae615bf3609f5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/423 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b31e0dd3b40e4a81ac922a226dbd27f7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d115dd581c2449d79b51dc334440fafa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/210 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c99e6244f8c744b1818cb2ed143b4877"}},"metadata":{}}]},{"cell_type":"code","source":"list_context = []\nfor _, context in dates_and_contexts:\n    list_context.append(context)\nlist_context = list(dict.fromkeys(list_context))","metadata":{"execution":{"iopub.status.busy":"2024-03-21T12:32:45.872747Z","iopub.execute_input":"2024-03-21T12:32:45.873585Z","iopub.status.idle":"2024-03-21T12:32:45.880353Z","shell.execute_reply.started":"2024-03-21T12:32:45.873547Z","shell.execute_reply":"2024-03-21T12:32:45.879351Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(list_context, columns=['texte'])\ndf[\"filename\"] = train.iloc[0][\"filename\"]\ndf","metadata":{"execution":{"iopub.status.busy":"2024-03-21T12:32:45.881643Z","iopub.execute_input":"2024-03-21T12:32:45.881924Z","iopub.status.idle":"2024-03-21T12:32:45.903827Z","shell.execute_reply.started":"2024-03-21T12:32:45.881902Z","shell.execute_reply":"2024-03-21T12:32:45.903000Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                                texte         filename\n0   Le 12 11 2019 Cour d appel d Agen chambre soci...  Agen_100515.txt\n1   GROUPE AZUR ASSURANCES IARD CAISSE PRIMAIRE D ...  Agen_100515.txt\n2   AZUR ASSURANCES IARD CAISSE PRIMAIRE D ASSURAN...  Agen_100515.txt\n3   SSURANCES IARD CAISSE PRIMAIRE D ASSURANCE MAL...  Agen_100515.txt\n4   NCES IARD CAISSE PRIMAIRE D ASSURANCE MALADIE ...  Agen_100515.txt\n5   ARD CAISSE PRIMAIRE D ASSURANCE MALADIE DE LOT...  Agen_100515.txt\n6   tion judiciaire de la société des transports M...  Agen_100515.txt\n7   n judiciaire de la société des transports MORE...  Agen_100515.txt\n8   udiciaire de la société des transports MOREL A...  Agen_100515.txt\n9   de la société des transports MOREL ARRET N COU...  Agen_100515.txt\n10  société des transports MOREL ARRET N COUR D AP...  Agen_100515.txt\n11  barreau d AGEN Madame Annie X Y du Laurier 473...  Agen_100515.txt\n12  FAIRES SANITAIRES ET SOCIALES AQUITAINE Cité A...  Agen_100515.txt\n13  FAIRES SANITAIRES ET SOCIALES AQUITAINE Cité A...  Agen_100515.txt\n14  FAIRES SANITAIRES ET SOCIALES AQUITAINE Cité A...  Agen_100515.txt\n15  FAIRES SANITAIRES ET SOCIALES AQUITAINE Cité A...  Agen_100515.txt\n16  Monsieur MILHET Président de Chambre Madame LA...  Agen_100515.txt\n17  nsieur MILHET Président de Chambre Madame LATR...  Agen_100515.txt\n18  ieur MILHET Président de Chambre Madame LATRAB...  Agen_100515.txt\n19  ILHET Président de Chambre Madame LATRABE Cons...  Agen_100515.txt\n20  par les magistrats du siège ayant assisté aux ...  Agen_100515.txt\n21  les magistrats du siège ayant assisté aux déba...  Agen_100515.txt\n22  magistrats du siège ayant assisté aux débats l...  Agen_100515.txt\n23  été avisées de la date à laquelle l arrêt sera...  Agen_100515.txt\n24  avisées de la date à laquelle l arrêt serait r...  Agen_100515.txt\n25  de la date à laquelle l arrêt serait rendu Le ...  Agen_100515.txt\n26  la date à laquelle l arrêt serait rendu Le 9 a...  Agen_100515.txt\n27  Sociale de LOT et GARONNE a dit que cet accide...  Agen_100515.txt\n28  de LOT et GARONNE a dit que cet accident était...  Agen_100515.txt\n29  LOT et GARONNE a dit que cet accident était dû...  Agen_100515.txt\n30  et GARONNE a dit que cet accident était dû à l...  Agen_100515.txt\n31  était dû à la faute inexcusable de la S A R L ...  Agen_100515.txt\n32  dû à la faute inexcusable de la S A R L TRANSP...  Agen_100515.txt\n33  à la faute inexcusable de la S A R L TRANSPORT...  Agen_100515.txt\n34  la faute inexcusable de la S A R L TRANSPORTS ...  Agen_100515.txt\n35  éjudices subis par Monsieur X s agissant des s...  Agen_100515.txt\n36  ices subis par Monsieur X s agissant des souff...  Agen_100515.txt\n37  bis par Monsieur X s agissant des souffrances ...  Agen_100515.txt\n38  s par Monsieur X s agissant des souffrances en...  Agen_100515.txt\n39  ère douloureux des interventions traitements e...  Agen_100515.txt\n40  e douloureux des interventions traitements et ...  Agen_100515.txt\n41  douloureux des interventions traitements et so...  Agen_100515.txt\n42  uloureux des interventions traitements et soin...  Agen_100515.txt\n43  cs par le premier juge Que la réparation du pr...  Agen_100515.txt\n44  e ou de la diminution des possibilités de prom...  Agen_100515.txt\n45  de la diminution des possibilités de promotion...  Agen_100515.txt\n46  diminution des possibilités de promotion profe...  Agen_100515.txt\n47  minution des possibilités de promotion profess...  Agen_100515.txt","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texte</th>\n      <th>filename</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Le 12 11 2019 Cour d appel d Agen chambre soci...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>GROUPE AZUR ASSURANCES IARD CAISSE PRIMAIRE D ...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AZUR ASSURANCES IARD CAISSE PRIMAIRE D ASSURAN...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SSURANCES IARD CAISSE PRIMAIRE D ASSURANCE MAL...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NCES IARD CAISSE PRIMAIRE D ASSURANCE MALADIE ...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>ARD CAISSE PRIMAIRE D ASSURANCE MALADIE DE LOT...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>tion judiciaire de la société des transports M...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>n judiciaire de la société des transports MORE...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>udiciaire de la société des transports MOREL A...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>de la société des transports MOREL ARRET N COU...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>société des transports MOREL ARRET N COUR D AP...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>barreau d AGEN Madame Annie X Y du Laurier 473...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>FAIRES SANITAIRES ET SOCIALES AQUITAINE Cité A...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>FAIRES SANITAIRES ET SOCIALES AQUITAINE Cité A...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>FAIRES SANITAIRES ET SOCIALES AQUITAINE Cité A...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>FAIRES SANITAIRES ET SOCIALES AQUITAINE Cité A...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Monsieur MILHET Président de Chambre Madame LA...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>nsieur MILHET Président de Chambre Madame LATR...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>ieur MILHET Président de Chambre Madame LATRAB...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>ILHET Président de Chambre Madame LATRABE Cons...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>par les magistrats du siège ayant assisté aux ...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>les magistrats du siège ayant assisté aux déba...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>magistrats du siège ayant assisté aux débats l...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>été avisées de la date à laquelle l arrêt sera...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>avisées de la date à laquelle l arrêt serait r...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>de la date à laquelle l arrêt serait rendu Le ...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>la date à laquelle l arrêt serait rendu Le 9 a...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Sociale de LOT et GARONNE a dit que cet accide...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>de LOT et GARONNE a dit que cet accident était...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>LOT et GARONNE a dit que cet accident était dû...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>et GARONNE a dit que cet accident était dû à l...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>était dû à la faute inexcusable de la S A R L ...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>dû à la faute inexcusable de la S A R L TRANSP...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>à la faute inexcusable de la S A R L TRANSPORT...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>la faute inexcusable de la S A R L TRANSPORTS ...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>éjudices subis par Monsieur X s agissant des s...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>ices subis par Monsieur X s agissant des souff...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>bis par Monsieur X s agissant des souffrances ...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>s par Monsieur X s agissant des souffrances en...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>ère douloureux des interventions traitements e...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>e douloureux des interventions traitements et ...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>douloureux des interventions traitements et so...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>uloureux des interventions traitements et soin...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>cs par le premier juge Que la réparation du pr...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>e ou de la diminution des possibilités de prom...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>de la diminution des possibilités de promotion...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>diminution des possibilités de promotion profe...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>minution des possibilités de promotion profess...</td>\n      <td>Agen_100515.txt</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# from tqdm import tqdm\n\n# data_to_append = []\n\n# for index, row in tqdm(train.iterrows(), total=train.shape[0]):\n#    text = row[\"texte\"]\n#    filename = row[\"filename\"]\n    \n#    dates_and_contexts = extract_dates_with_context_from_long_text(text, model, tokenizer, N_BATCHES, CONTEXT)\n    \n#    contexts = \" \".join([context for _, context in dates_and_contexts])\n    \n#    data_to_append.append({\"filename\": filename, \"contexts\": contexts})\n\n# results_df = pd.DataFrame(data_to_append, columns=[\"filename\", \"contexts\"])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T12:37:21.456618Z","iopub.execute_input":"2024-03-21T12:37:21.457431Z","iopub.status.idle":"2024-03-21T12:37:32.087778Z","shell.execute_reply.started":"2024-03-21T12:37:21.457398Z","shell.execute_reply":"2024-03-21T12:37:32.086823Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"100%|██████████| 2/2 [00:10<00:00,  5.31s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"results_df = pd.read_csv(\"/kaggle/input/dates-dataset/passages_dates.csv\", index_col=[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:11:03.575450Z","iopub.execute_input":"2024-03-21T14:11:03.575899Z","iopub.status.idle":"2024-03-21T14:11:04.583089Z","shell.execute_reply.started":"2024-03-21T14:11:03.575858Z","shell.execute_reply":"2024-03-21T14:11:04.582201Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"results_df.rename(columns={\"contexts\": \"texte\"}, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:11:04.584343Z","iopub.execute_input":"2024-03-21T14:11:04.584667Z","iopub.status.idle":"2024-03-21T14:11:04.589882Z","shell.execute_reply.started":"2024-03-21T14:11:04.584643Z","shell.execute_reply":"2024-03-21T14:11:04.588974Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"results_df","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:11:04.591357Z","iopub.execute_input":"2024-03-21T14:11:04.591643Z","iopub.status.idle":"2024-03-21T14:11:04.615666Z","shell.execute_reply.started":"2024-03-21T14:11:04.591620Z","shell.execute_reply":"2024-03-21T14:11:04.614788Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                  filename                                              texte\n0          Agen_100515.txt  Le 12 11 2019 Cour d appel d Agen chambre soci...\n1         Agen_1100752.txt  Le 12 11 2019 Cour d appel d Agen chambre civi...\n2            Agen_1613.txt  Le 12 11 2019 Cour d appel d Agen Audience pub...\n3            Agen_2118.txt  Le 12 11 2019 Cour d appel d Agen Audience pub...\n4           Agen_21229.txt  Le 12 11 2019 Cour d appel d Agen Audience pub...\n..                     ...                                                ...\n765  Versailles_602516.txt  Le 12 11 2019 Cour d appel de Versailles ct003...\n766  Versailles_605885.txt  Le 12 11 2019 Cour d appel de Versailles ct008...\n767   Versailles_61934.txt  Le 12 11 2019 Cour d appel de Versailles ct008...\n768   Versailles_67325.txt  Le 12 11 2019 Cour d appel de Versailles ct008...\n769  Versailles_903789.txt  Le 12 11 2019 Cour d appel de Versailles 5ème ...\n\n[770 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>texte</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Agen_100515.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen chambre soci...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Agen_1100752.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen chambre civi...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Agen_1613.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen Audience pub...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Agen_2118.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen Audience pub...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Agen_21229.txt</td>\n      <td>Le 12 11 2019 Cour d appel d Agen Audience pub...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>Versailles_602516.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles ct003...</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>Versailles_605885.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles ct008...</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>Versailles_61934.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles ct008...</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>Versailles_67325.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles ct008...</td>\n    </tr>\n    <tr>\n      <th>769</th>\n      <td>Versailles_903789.txt</td>\n      <td>Le 12 11 2019 Cour d appel de Versailles 5ème ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>770 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"results_df = results_df[:2]","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:11:04.616778Z","iopub.execute_input":"2024-03-21T14:11:04.617183Z","iopub.status.idle":"2024-03-21T14:11:04.621864Z","shell.execute_reply.started":"2024-03-21T14:11:04.617147Z","shell.execute_reply":"2024-03-21T14:11:04.620943Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# RAG","metadata":{}},{"cell_type":"code","source":"model = transformers.AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", device_map='auto')\ntokenizer = transformers.AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:56:06.930237Z","iopub.execute_input":"2024-03-21T13:56:06.930575Z","iopub.status.idle":"2024-03-21T13:58:36.562946Z","shell.execute_reply.started":"2024-03-21T13:56:06.930550Z","shell.execute_reply":"2024-03-21T13:58:36.561824Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c16752230d9541f5b7c12160b60c1804"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f192a6450e1940d5a506422d81d0b1ca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c327c80aabb049d5bc9508942dc3f467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39d3864970cb4451a744340b4b189e5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c614056258a84bf9b21ed12a60081e70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9df3cf71de114d85b788f2cec5b39d62"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"70d4d7db27a844e3a833dc343bb1b0e8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3fdc7417c9dc48bb8c1462df47cecff4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdd85d1fc3a24ed7a751fb022582e3a6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3aa73822ebf447b38b3da1cca759e992"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"edce2460bf1f43a99de882647e0c433e"}},"metadata":{}}]},{"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import sent_tokenize\n\nnltk.download('punkt') # Décommente cette ligne si 'punkt' n'a pas déjà été téléchargé\n\ndef preprocess_documents(df_or_series):\n    pages_content = []\n    \n    # Vérifie si l'objet est une Series et le convertit en DataFrame si nécessaire\n    if isinstance(df_or_series, pd.Series):\n        df = df_or_series.to_frame().transpose()\n    else:\n        df = df_or_series\n    \n    for index, row in df.iterrows():\n        texte = row[\"texte\"]\n        name = row[\"filename\"]\n        \n        # Découpe le texte en phrases\n        phrases = sent_tokenize(texte)\n        \n        for phrase in phrases:\n            texte_doc = Document(page_content=phrase,\n                                 metadata={'name': name})\n            pages_content.append(texte_doc)\n        \n    return pages_content","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:58:36.565164Z","iopub.execute_input":"2024-03-21T13:58:36.565497Z","iopub.status.idle":"2024-03-21T13:58:37.347864Z","shell.execute_reply.started":"2024-03-21T13:58:36.565470Z","shell.execute_reply":"2024-03-21T13:58:37.346844Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"content = preprocess_documents(results_df)\nembedding_model = SentenceTransformerEmbeddings(model_name='multi-qa-distilbert-cos-v1')\nfaiss_index = FAISS.from_documents(content, embedding_model)\nretriever = faiss_index.as_retriever(search_kwargs={'k': 3})","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:08:35.767418Z","iopub.execute_input":"2024-03-21T14:08:35.768170Z","iopub.status.idle":"2024-03-21T14:08:37.459172Z","shell.execute_reply.started":"2024-03-21T14:08:35.768136Z","shell.execute_reply":"2024-03-21T14:08:37.458309Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"text_generation_pipeline = transformers.pipeline(\n    model=model,\n    tokenizer=tokenizer,\n    task=\"text-generation\",\n    temperature=0,\n    repetition_penalty=1.2,\n    return_full_text=True,\n    max_new_tokens=2000)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:08:38.090836Z","iopub.execute_input":"2024-03-21T14:08:38.091219Z","iopub.status.idle":"2024-03-21T14:08:38.096848Z","shell.execute_reply.started":"2024-03-21T14:08:38.091190Z","shell.execute_reply":"2024-03-21T14:08:38.095696Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"mistral_llm = HuggingFacePipeline(pipeline=text_generation_pipeline)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:08:38.949353Z","iopub.execute_input":"2024-03-21T14:08:38.949727Z","iopub.status.idle":"2024-03-21T14:08:38.955707Z","shell.execute_reply.started":"2024-03-21T14:08:38.949697Z","shell.execute_reply":"2024-03-21T14:08:38.954730Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"qa = ConversationalRetrievalChain.from_llm(llm=mistral_llm,\n                                           retriever=retriever,\n                                           return_source_documents=True,\n                                           verbose=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:08:39.635737Z","iopub.execute_input":"2024-03-21T14:08:39.636487Z","iopub.status.idle":"2024-03-21T14:08:39.641733Z","shell.execute_reply.started":"2024-03-21T14:08:39.636452Z","shell.execute_reply":"2024-03-21T14:08:39.640796Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"queries = [\"Quelle est la date de l'accident?\"]\nfor query in queries :\n\n    if query == \"Quelle est la date de l'accident?\":\n        result = qa({\"question\" : f\"\"\"Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n    On va te demander les informations suivantes : Sexe de la victime, date de l'accident, date de consolidation.\n    La date de l'accident correspond à la date à laquelle l'accident s'est produit. Elle est toujours quelque part dans le document (généralement au début) sauf dans de très rares cas.\n    voici la demande : {query} ATTENTION: Tu me renverras la date au format MM-DD-AAAA\n\"\"\",\n    \"chat_history\": []})\n\n    elif query == \"Quelle est la date de consolidation?\":\n        result = qa({\"question\" : f\"\"\"Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n    On va te demander les informations suivantes : Sexe de la victime, date de l'accident, date de consolidation.\n    La date de consolidation est la date à laquelle les blessures de la victime sont devenues stables et ont été déclarées définitives par un médecin. L'information devrait être présente dans la plupart des cas mais parfois elle est soit manquante (tu afficheras la valeur \"n.c.\") soit non applicable (tu afficheras la valeur \"n.a.\") si la blessure n'a pas stabilisé avant le décès de la victime.\n    voici la demande : {query} \"\"\",\n    \"chat_history\": []})\n","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:08:40.261156Z","iopub.execute_input":"2024-03-21T14:08:40.261745Z","iopub.status.idle":"2024-03-21T14:08:42.232317Z","shell.execute_reply.started":"2024-03-21T14:08:40.261713Z","shell.execute_reply":"2024-03-21T14:08:42.230947Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n  warn_deprecated(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n  \"\"\"\nSetting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","output_type":"stream"},{"name":"stdout","text":"Unexpected exception formatting exception. Falling back to standard exception\n","output_type":"stream"},{"name":"stderr","text":"Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"/tmp/ipykernel_34/453977644.py\", line 5, in <module>\n    result = qa({\"question\" : f\"\"\"Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 378, in __call__\n    return self.invoke(\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 163, in invoke\n    raise e\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 153, in invoke\n    self._call(inputs, run_manager=run_manager)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/conversational_retrieval/base.py\", line 166, in _call\n    answer = self.combine_docs_chain.run(\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 550, in run\n    return self(kwargs, callbacks=callbacks, tags=tags, metadata=metadata)[\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 378, in __call__\n    return self.invoke(\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 163, in invoke\n    raise e\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 153, in invoke\n    self._call(inputs, run_manager=run_manager)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/combine_documents/base.py\", line 137, in _call\n    output, extra_return_dict = self.combine_docs(\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/combine_documents/stuff.py\", line 244, in combine_docs\n    return self.llm_chain.predict(callbacks=callbacks, **inputs), {}\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/llm.py\", line 293, in predict\n    return self(kwargs, callbacks=callbacks)[self.output_key]\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/_api/deprecation.py\", line 145, in warning_emitting_wrapper\n    return wrapped(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 378, in __call__\n    return self.invoke(\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 163, in invoke\n    raise e\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/base.py\", line 153, in invoke\n    self._call(inputs, run_manager=run_manager)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/llm.py\", line 103, in _call\n    response = self.generate([inputs], run_manager=run_manager)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain/chains/llm.py\", line 115, in generate\n    return self.llm.generate_prompt(\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 569, in generate_prompt\n    return self.generate(prompt_strings, stop=stop, callbacks=callbacks, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 748, in generate\n    output = self._generate_helper(\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 606, in _generate_helper\n    raise e\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_core/language_models/llms.py\", line 593, in _generate_helper\n    self._generate(\n  File \"/opt/conda/lib/python3.10/site-packages/langchain_community/llms/huggingface_pipeline.py\", line 266, in _generate\n    responses = self.pipeline(\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 241, in __call__\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1177, in __call__\n    is_iterable = is_dataset or is_generator or is_list\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py\", line 124, in __next__\n    item = next(self.iterator)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py\", line 125, in __next__\n    processed = self.infer(item, **self.params)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/base.py\", line 1102, in forward\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/pipelines/text_generation.py\", line 328, in _forward\n    out_b = generated_sequence.shape[0]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n    return func(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 1544, in generate\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py\", line 2404, in greedy_search\n    model_kwargs[\"cache_position\"] = torch.arange(cur_len, device=input_ids.device)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\", line 1157, in forward\n    outputs = self.model(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\", line 1042, in forward\n    layer_outputs = decoder_layer(\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\", line 754, in forward\n    hidden_states = self.input_layernorm(hidden_states)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1518, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\", line 1527, in _call_impl\n    return forward_call(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/accelerate/hooks.py\", line 166, in new_forward\n    output = module._old_forward(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/transformers/models/mistral/modeling_mistral.py\", line 88, in forward\n    return self.weight * hidden_states.to(input_dtype)\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 432.00 MiB. GPU 0 has a total capacty of 14.75 GiB of which 357.06 MiB is free. Process 3811 has 14.40 GiB memory in use. Of the allocated memory 14.24 GiB is allocated by PyTorch, and 29.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n    stb = self.InteractiveTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n    return FormattedTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n    return VerboseTB.structured_traceback(\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n    frames.append(self.format_record(record))\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n    frame_info.lines, Colors, self.has_colors, lvals\n  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n    return self._sd.lines\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 734, in lines\n    pieces = self.included_pieces\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 681, in included_pieces\n    pos = scope_pieces.index(self.executing_piece)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n    value = obj.__dict__[self.func.__name__] = self.func(obj)\n  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 660, in executing_piece\n    return only(\n  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 116, in only\n    raise NotOneValueFound('Expected one value, found 0')\nexecuting.executing.NotOneValueFound: Expected one value, found 0\n","output_type":"stream"}]},{"cell_type":"code","source":"for element in result[\"source_documents\"]:\n    source = f'\\n- {element.metadata[\"name\"]}'\n    print(source)","metadata":{"execution":{"iopub.status.busy":"2024-03-21T14:08:42.233346Z","iopub.status.idle":"2024-03-21T14:08:42.233791Z","shell.execute_reply.started":"2024-03-21T14:08:42.233563Z","shell.execute_reply":"2024-03-21T14:08:42.233581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(result['answer'])","metadata":{"execution":{"iopub.status.busy":"2024-03-21T13:22:48.213707Z","iopub.execute_input":"2024-03-21T13:22:48.214033Z","iopub.status.idle":"2024-03-21T13:22:48.223618Z","shell.execute_reply.started":"2024-03-21T13:22:48.214004Z","shell.execute_reply":"2024-03-21T13:22:48.222695Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n\navisées de la date à laquelle l arrêt serait rendu Le 9 avril 1991 Monsieur X a été victime d un accident du travail au cours duquel il a été gravement blessé Suivant jugement en date du 24 avril 1997 confirmé par arrêt de la Cour en date du 30 mars 1999 le Tribunal des Affaires de Sé\n\nété avisées de la date à laquelle l arrêt serait rendu Le 9 avril 1991 Monsieur X a été victime d un accident du travail au cours duquel il a été gravement blessé Suivant jugement en date du 24 avril 1997 confirmé par arrêt de la Cour en date du 30 mars 1999 le Tribunal des Affaires de Sé\n\nde la date à laquelle l arrêt serait rendu Le 9 avril 1991 Monsieur X a été victime d un accident du travail au cours duquel il a été gravement blessé Suivant jugement en date du 24 avril 1997 confirmé par arrêt de la Cour en date du 30 mars 1999 le Tribunal des Affaires de Sé\n\nQuestion: Tu es un assistant juridique. Tu vas recevoir plusieurs textes juridiques et tu vas devoir répondre à la recherché une ou des informations demandée(s) par l'utilisateur à partir des documents données.\n    On va te demander les informations suivantes : Sexe de la victime, date de l'accident, date de consolidation.\n    La date de l'accident correspond à la date à laquelle l'accident s'est produit. Elle est toujours quelque part dans le document (généralement au début) sauf dans de très rares cas.\n    voici la demande : Quelle est la date de l'accident? ATTENTION: Tu me renverras la date au format MM-DD-AAAA\n\nHelpful Answer: The date of the accident is April 9, 1991.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}