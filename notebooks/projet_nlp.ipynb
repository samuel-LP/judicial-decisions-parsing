{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":7765031,"sourceType":"datasetVersion","datasetId":4541802}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-10T10:45:31.721680Z","iopub.execute_input":"2024-03-10T10:45:31.722080Z","iopub.status.idle":"2024-03-10T10:45:47.514638Z","shell.execute_reply.started":"2024-03-10T10:45:31.722050Z","shell.execute_reply":"2024-03-10T10:45:47.513652Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-03-10 10:45:33.752996: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-10 10:45:33.753111: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-10 10:45:33.885435: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/data-train-test/train_data.csv\")\ntest = pd.read_csv(\"/kaggle/input/data-train-test/test_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:47.516109Z","iopub.execute_input":"2024-03-10T10:45:47.516633Z","iopub.status.idle":"2024-03-10T10:45:48.142081Z","shell.execute_reply.started":"2024-03-10T10:45:47.516607Z","shell.execute_reply":"2024-03-10T10:45:48.141187Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:48.143251Z","iopub.execute_input":"2024-03-10T10:45:48.143555Z","iopub.status.idle":"2024-03-10T10:45:48.164888Z","shell.execute_reply.started":"2024-03-10T10:45:48.143531Z","shell.execute_reply":"2024-03-10T10:45:48.163888Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   ID          filename                                              texte  \\\n0   0   Agen_100515.txt  Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...   \n1   1  Agen_1100752.txt  Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...   \n2   2     Agen_1613.txt  Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...   \n3   3     Agen_2118.txt  Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...   \n4   4    Agen_21229.txt  Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...   \n\n    sexe date_accident date_consolidation  \n0  homme    1991-04-09               n.c.  \n1  homme    2005-06-10         2010-01-19  \n2  femme    1997-09-26               n.c.  \n3  femme    1982-08-07         1982-11-07  \n4  homme    1996-11-26               n.c.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>filename</th>\n      <th>texte</th>\n      <th>sexe</th>\n      <th>date_accident</th>\n      <th>date_consolidation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Agen_100515.txt</td>\n      <td>Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...</td>\n      <td>homme</td>\n      <td>1991-04-09</td>\n      <td>n.c.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Agen_1100752.txt</td>\n      <td>Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...</td>\n      <td>homme</td>\n      <td>2005-06-10</td>\n      <td>2010-01-19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Agen_1613.txt</td>\n      <td>Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...</td>\n      <td>femme</td>\n      <td>1997-09-26</td>\n      <td>n.c.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Agen_2118.txt</td>\n      <td>Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...</td>\n      <td>femme</td>\n      <td>1982-08-07</td>\n      <td>1982-11-07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Agen_21229.txt</td>\n      <td>Le : 12/11/2019\\n \\n \\nCour d’appel d’Agen \\n ...</td>\n      <td>homme</td>\n      <td>1996-11-26</td>\n      <td>n.c.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def remove_newlines(df):\n    df = df.replace(\"\\n\", '', regex=True)\n    return df\ntrain = remove_newlines(train)\ntest = remove_newlines(test)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:48.167715Z","iopub.execute_input":"2024-03-10T10:45:48.168419Z","iopub.status.idle":"2024-03-10T10:45:48.284729Z","shell.execute_reply.started":"2024-03-10T10:45:48.168390Z","shell.execute_reply":"2024-03-10T10:45:48.283863Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:48.285872Z","iopub.execute_input":"2024-03-10T10:45:48.286174Z","iopub.status.idle":"2024-03-10T10:45:48.302170Z","shell.execute_reply.started":"2024-03-10T10:45:48.286150Z","shell.execute_reply":"2024-03-10T10:45:48.301002Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"   ID          filename                                              texte  \\\n0   0   Agen_100515.txt  Le : 12/11/2019  Cour d’appel d’Agen  chambre ...   \n1   1  Agen_1100752.txt  Le : 12/11/2019  Cour d’appel d’Agen  chambre ...   \n2   2     Agen_1613.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n3   3     Agen_2118.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n4   4    Agen_21229.txt  Le : 12/11/2019  Cour d’appel d’Agen  Audience...   \n\n    sexe date_accident date_consolidation  \n0  homme    1991-04-09               n.c.  \n1  homme    2005-06-10         2010-01-19  \n2  femme    1997-09-26               n.c.  \n3  femme    1982-08-07         1982-11-07  \n4  homme    1996-11-26               n.c.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>filename</th>\n      <th>texte</th>\n      <th>sexe</th>\n      <th>date_accident</th>\n      <th>date_consolidation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Agen_100515.txt</td>\n      <td>Le : 12/11/2019  Cour d’appel d’Agen  chambre ...</td>\n      <td>homme</td>\n      <td>1991-04-09</td>\n      <td>n.c.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Agen_1100752.txt</td>\n      <td>Le : 12/11/2019  Cour d’appel d’Agen  chambre ...</td>\n      <td>homme</td>\n      <td>2005-06-10</td>\n      <td>2010-01-19</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Agen_1613.txt</td>\n      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n      <td>femme</td>\n      <td>1997-09-26</td>\n      <td>n.c.</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>Agen_2118.txt</td>\n      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n      <td>femme</td>\n      <td>1982-08-07</td>\n      <td>1982-11-07</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Agen_21229.txt</td>\n      <td>Le : 12/11/2019  Cour d’appel d’Agen  Audience...</td>\n      <td>homme</td>\n      <td>1996-11-26</td>\n      <td>n.c.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in [\"sexe\", \"date_accident\", \"date_consolidation\"]:\n    print(\"\\n\",\"-\"*5, col, \"-\"*5)\n    print(train[col].value_counts(normalize=True)*100)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:48.303878Z","iopub.execute_input":"2024-03-10T10:45:48.304978Z","iopub.status.idle":"2024-03-10T10:45:48.326971Z","shell.execute_reply.started":"2024-03-10T10:45:48.304936Z","shell.execute_reply":"2024-03-10T10:45:48.325795Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"\n ----- sexe -----\nsexe\nhomme    72.597403\nfemme    26.753247\nn.c.      0.649351\nName: proportion, dtype: float64\n\n ----- date_accident -----\ndate_accident\nn.c.          3.506494\n2002-06-13    0.389610\n2005-10-25    0.389610\n1995-07-27    0.259740\n2004-08-08    0.259740\n                ...   \n2007-05-24    0.129870\n2010-05-06    0.129870\n2008-09-26    0.129870\n2009-10-12    0.129870\n2007-10-13    0.129870\nName: proportion, Length: 697, dtype: float64\n\n ----- date_consolidation -----\ndate_consolidation\nn.c.          28.441558\nn.a.          13.246753\n2004-09-15     0.389610\n2005-03-02     0.389610\n2007-09-24     0.389610\n                ...    \n2005-06-12     0.129870\n1996-06-14     0.129870\n1993-07-16     0.129870\n2009-02-15     0.129870\n2006-04-28     0.129870\nName: proportion, Length: 413, dtype: float64\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[train[\"sexe\"] != 'n.c.']","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:48.328430Z","iopub.execute_input":"2024-03-10T10:45:48.328868Z","iopub.status.idle":"2024-03-10T10:45:48.338502Z","shell.execute_reply.started":"2024-03-10T10:45:48.328830Z","shell.execute_reply":"2024-03-10T10:45:48.337556Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.hist(train[\"sexe\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:48.339691Z","iopub.execute_input":"2024-03-10T10:45:48.340018Z","iopub.status.idle":"2024-03-10T10:45:48.552655Z","shell.execute_reply.started":"2024-03-10T10:45:48.339992Z","shell.execute_reply":"2024-03-10T10:45:48.551568Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"(array([559.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 206.]),\n array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n <BarContainer object of 10 artists>)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAioAAAGdCAYAAAA8F1jjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAf10lEQVR4nO3df2zU9eHH8de1pQf9cVdb6R1ISyFMaSeI/Bg9xwSxtrJiNJRMGcFqiG5YyKARsQvy01nGFnEuIM4puE2GY4s6YSCIAhkcPyzBID+qEE27wLU41zvAtKXt+/vH0ttOcF8OWu7d+nwkn4R7f96fu/enIfk8c/3c1WGMMQIAALBQXKwXAAAA8HUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWSoj1Aq5EW1ubTp06pdTUVDkcjlgvBwAAXAZjjM6ePau+ffsqLu7y3ivpkqFy6tQpZWVlxXoZAADgCtTW1qpfv36XNbdLhkpqaqqkf5+oy+WK8WoAAMDlCIVCysrKCl/HL0eXDJX2X/e4XC5CBQCALiaa2za4mRYAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANZKiPUCbJTz5KZYLyFqny0rjvUSAADocLyjAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALBWVKGyaNEiORyOiG3w4MHh/Y2NjSorK1NGRoZSUlJUUlKiurq6iOeoqalRcXGxkpKSlJmZqblz56qlpaVjzgYAAHQrCdEe8O1vf1vvvvvuf54g4T9PMWfOHG3atEkbNmyQ2+3WzJkzNWnSJO3evVuS1NraquLiYnm9Xu3Zs0enT5/Wgw8+qB49euiZZ57pgNMBAADdSdShkpCQIK/Xe9F4MBjUyy+/rHXr1mn8+PGSpDVr1ig3N1d79+5Vfn6+tm7dqqNHj+rdd9+Vx+PRsGHDtHTpUs2bN0+LFi1SYmLi1Z8RAADoNqK+R+WTTz5R3759NXDgQE2dOlU1NTWSpKqqKl24cEEFBQXhuYMHD1Z2drb8fr8kye/3a8iQIfJ4POE5RUVFCoVCOnLkyNe+ZlNTk0KhUMQGAAC6v6hCZfTo0Vq7dq22bNmiF154QZ9++qm+973v6ezZswoEAkpMTFRaWlrEMR6PR4FAQJIUCAQiIqV9f/u+r1NZWSm32x3esrKyolk2AADooqL61c+ECRPC/x46dKhGjx6t/v37609/+pN69erV4YtrV1FRofLy8vDjUChErAAA8A1wVR9PTktL04033qgTJ07I6/WqublZDQ0NEXPq6urC97R4vd6LPgXU/vhS9720czqdcrlcERsAAOj+ripUzp07p5MnT6pPnz4aMWKEevTooe3bt4f3V1dXq6amRj6fT5Lk8/l0+PBh1dfXh+ds27ZNLpdLeXl5V7MUAADQDUX1q5/HH39c99xzj/r3769Tp05p4cKFio+P15QpU+R2uzV9+nSVl5crPT1dLpdLs2bNks/nU35+viSpsLBQeXl5mjZtmpYvX65AIKD58+errKxMTqezU04QAAB0XVGFyj/+8Q9NmTJF//znP9W7d2+NGTNGe/fuVe/evSVJK1asUFxcnEpKStTU1KSioiKtWrUqfHx8fLw2btyoGTNmyOfzKTk5WaWlpVqyZEnHnhUAAOgWHMYYE+tFRCsUCsntdisYDHbK/So5T27q8OfsbJ8tK471EgAA+J+u5PrN3/oBAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFjrqkJl2bJlcjgcmj17dnissbFRZWVlysjIUEpKikpKSlRXVxdxXE1NjYqLi5WUlKTMzEzNnTtXLS0tV7MUAADQDV1xqBw4cEAvvviihg4dGjE+Z84cvf3229qwYYN27typU6dOadKkSeH9ra2tKi4uVnNzs/bs2aNXX31Va9eu1YIFC678LAAAQLd0RaFy7tw5TZ06VS+99JKuu+668HgwGNTLL7+sZ599VuPHj9eIESO0Zs0a7dmzR3v37pUkbd26VUePHtUf/vAHDRs2TBMmTNDSpUu1cuVKNTc3d8xZAQCAbuGKQqWsrEzFxcUqKCiIGK+qqtKFCxcixgcPHqzs7Gz5/X5Jkt/v15AhQ+TxeMJzioqKFAqFdOTIkUu+XlNTk0KhUMQGAAC6v4RoD1i/fr0OHjyoAwcOXLQvEAgoMTFRaWlpEeMej0eBQCA8578jpX1/+75Lqays1OLFi6NdKgAA6OKiekeltrZWP/nJT/Taa6+pZ8+enbWmi1RUVCgYDIa32traa/baAAAgdqIKlaqqKtXX12v48OFKSEhQQkKCdu7cqeeff14JCQnyeDxqbm5WQ0NDxHF1dXXyer2SJK/Xe9GngNoft8/5KqfTKZfLFbEBAIDuL6pQufPOO3X48GEdOnQovI0cOVJTp04N/7tHjx7avn17+Jjq6mrV1NTI5/NJknw+nw4fPqz6+vrwnG3btsnlcikvL6+DTgsAAHQHUd2jkpqaqptvvjliLDk5WRkZGeHx6dOnq7y8XOnp6XK5XJo1a5Z8Pp/y8/MlSYWFhcrLy9O0adO0fPlyBQIBzZ8/X2VlZXI6nR10WgAAoDuI+mba/8+KFSsUFxenkpISNTU1qaioSKtWrQrvj4+P18aNGzVjxgz5fD4lJyertLRUS5Ys6eilAACALs5hjDGxXkS0QqGQ3G63gsFgp9yvkvPkpg5/zs722bLiWC8BAID/6Uqu3/ytHwAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtaIKlRdeeEFDhw6Vy+WSy+WSz+fT5s2bw/sbGxtVVlamjIwMpaSkqKSkRHV1dRHPUVNTo+LiYiUlJSkzM1Nz585VS0tLx5wNAADoVqIKlX79+mnZsmWqqqrSBx98oPHjx+vee+/VkSNHJElz5szR22+/rQ0bNmjnzp06deqUJk2aFD6+tbVVxcXFam5u1p49e/Tqq69q7dq1WrBgQceeFQAA6BYcxhhzNU+Qnp6uX/ziF5o8ebJ69+6tdevWafLkyZKk48ePKzc3V36/X/n5+dq8ebMmTpyoU6dOyePxSJJWr16tefPm6cyZM0pMTLys1wyFQnK73QoGg3K5XFez/EvKeXJThz9nZ/tsWXGslwAAwP90JdfvK75HpbW1VevXr9f58+fl8/lUVVWlCxcuqKCgIDxn8ODBys7Olt/vlyT5/X4NGTIkHCmSVFRUpFAoFH5X5lKampoUCoUiNgAA0P1FHSqHDx9WSkqKnE6nfvzjH+uNN95QXl6eAoGAEhMTlZaWFjHf4/EoEAhIkgKBQESktO9v3/d1Kisr5Xa7w1tWVla0ywYAAF1Q1KFy00036dChQ9q3b59mzJih0tJSHT16tDPWFlZRUaFgMBjeamtrO/X1AACAHRKiPSAxMVGDBg2SJI0YMUIHDhzQr371K91///1qbm5WQ0NDxLsqdXV18nq9kiSv16v9+/dHPF/7p4La51yK0+mU0+mMdqkAAKCLu+rvUWlra1NTU5NGjBihHj16aPv27eF91dXVqqmpkc/nkyT5fD4dPnxY9fX14Tnbtm2Ty+VSXl7e1S4FAAB0M1G9o1JRUaEJEyYoOztbZ8+e1bp167Rjxw698847crvdmj59usrLy5Weni6Xy6VZs2bJ5/MpPz9fklRYWKi8vDxNmzZNy5cvVyAQ0Pz581VWVsY7JgAA4CJRhUp9fb0efPBBnT59Wm63W0OHDtU777yju+66S5K0YsUKxcXFqaSkRE1NTSoqKtKqVavCx8fHx2vjxo2aMWOGfD6fkpOTVVpaqiVLlnTsWQEAgG7hqr9HJRb4HpWL8T0qAADbXdPvUQEAAOhshAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGsRKgAAwFqECgAAsBahAgAArEWoAAAAaxEqAADAWoQKAACwFqECAACsRagAAABrESoAAMBahAoAALAWoQIAAKxFqAAAAGtFFSqVlZUaNWqUUlNTlZmZqfvuu0/V1dURcxobG1VWVqaMjAylpKSopKREdXV1EXNqampUXFyspKQkZWZmau7cuWppabn6swEAAN1KQjSTd+7cqbKyMo0aNUotLS366U9/qsLCQh09elTJycmSpDlz5mjTpk3asGGD3G63Zs6cqUmTJmn37t2SpNbWVhUXF8vr9WrPnj06ffq0HnzwQfXo0UPPPPNMx58hAAAxlPPkplgv4Yp8tqw41kuQJDmMMeZKDz5z5owyMzO1c+dO3X777QoGg+rdu7fWrVunyZMnS5KOHz+u3Nxc+f1+5efna/PmzZo4caJOnTolj8cjSVq9erXmzZunM2fOKDEx8f993VAoJLfbrWAwKJfLdaXL/1pd8T+VLf+hAACRuuI1Reqc68qVXL+v6h6VYDAoSUpPT5ckVVVV6cKFCyooKAjPGTx4sLKzs+X3+yVJfr9fQ4YMCUeKJBUVFSkUCunIkSOXfJ2mpiaFQqGIDQAAdH9XHCptbW2aPXu2vvvd7+rmm2+WJAUCASUmJiotLS1irsfjUSAQCM/570hp39++71IqKyvldrvDW1ZW1pUuGwAAdCFXHCplZWX66KOPtH79+o5czyVVVFQoGAyGt9ra2k5/TQAAEHtR3UzbbubMmdq4caN27dqlfv36hce9Xq+am5vV0NAQ8a5KXV2dvF5veM7+/fsjnq/9U0Htc77K6XTK6XReyVIBAEAXFtU7KsYYzZw5U2+88Ybee+89DRgwIGL/iBEj1KNHD23fvj08Vl1drZqaGvl8PkmSz+fT4cOHVV9fH56zbds2uVwu5eXlXc25AACAbiaqd1TKysq0bt06vfXWW0pNTQ3fU+J2u9WrVy+53W5Nnz5d5eXlSk9Pl8vl0qxZs+Tz+ZSfny9JKiwsVF5enqZNm6bly5crEAho/vz5Kisr410TAAAQIapQeeGFFyRJ48aNixhfs2aNHnroIUnSihUrFBcXp5KSEjU1NamoqEirVq0Kz42Pj9fGjRs1Y8YM+Xw+JScnq7S0VEuWLLm6MwEAAN1OVKFyOV+50rNnT61cuVIrV6782jn9+/fX3/72t2heGgAAfAPxt34AAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANaKOlR27dqle+65R3379pXD4dCbb74Zsd8YowULFqhPnz7q1auXCgoK9Mknn0TM+eKLLzR16lS5XC6lpaVp+vTpOnfu3FWdCAAA6H6iDpXz58/rlltu0cqVKy+5f/ny5Xr++ee1evVq7du3T8nJySoqKlJjY2N4ztSpU3XkyBFt27ZNGzdu1K5du/Too49e+VkAAIBuKSHaAyZMmKAJEyZccp8xRs8995zmz5+ve++9V5L0u9/9Th6PR2+++aYeeOABHTt2TFu2bNGBAwc0cuRISdKvf/1rff/739cvf/lL9e3b9ypOBwAAdCcdeo/Kp59+qkAgoIKCgvCY2+3W6NGj5ff7JUl+v19paWnhSJGkgoICxcXFad++fZd83qamJoVCoYgNAAB0fx0aKoFAQJLk8Xgixj0eT3hfIBBQZmZmxP6EhASlp6eH53xVZWWl3G53eMvKyurIZQMAAEt1iU/9VFRUKBgMhrfa2tpYLwkAAFwDHRoqXq9XklRXVxcxXldXF97n9XpVX18fsb+lpUVffPFFeM5XOZ1OuVyuiA0AAHR/HRoqAwYMkNfr1fbt28NjoVBI+/btk8/nkyT5fD41NDSoqqoqPOe9995TW1ubRo8e3ZHLAQAAXVzUn/o5d+6cTpw4EX786aef6tChQ0pPT1d2drZmz56tp59+Wt/61rc0YMAAPfXUU+rbt6/uu+8+SVJubq7uvvtuPfLII1q9erUuXLigmTNn6oEHHuATPwAAIELUofLBBx/ojjvuCD8uLy+XJJWWlmrt2rV64okndP78eT366KNqaGjQmDFjtGXLFvXs2TN8zGuvvaaZM2fqzjvvVFxcnEpKSvT88893wOkAAIDuxGGMMbFeRLRCoZDcbreCwWCn3K+S8+SmDn/OzvbZsuJYLwEAcAld8Zoidc515Uqu313iUz8AAOCbiVABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLUIFQAAYC1CBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGCtmIbKypUrlZOTo549e2r06NHav39/LJcDAAAsE7NQef3111VeXq6FCxfq4MGDuuWWW1RUVKT6+vpYLQkAAFgmZqHy7LPP6pFHHtHDDz+svLw8rV69WklJSXrllVditSQAAGCZhFi8aHNzs6qqqlRRUREei4uLU0FBgfx+/0Xzm5qa1NTUFH4cDAYlSaFQqFPW19b0Zac8b2fqrJ8FAODqdMVritQ515X25zTGXPYxMQmVzz//XK2trfJ4PBHjHo9Hx48fv2h+ZWWlFi9efNF4VlZWp62xq3E/F+sVAAC6k868rpw9e1Zut/uy5sYkVKJVUVGh8vLy8OO2tjZ98cUXysjIkMPh6NDXCoVCysrKUm1trVwuV4c+NwAAXUFnXQuNMTp79qz69u172cfEJFSuv/56xcfHq66uLmK8rq5OXq/3ovlOp1NOpzNiLC0trTOXKJfLRagAAL7ROuNaeLnvpLSLyc20iYmJGjFihLZv3x4ea2tr0/bt2+Xz+WKxJAAAYKGY/eqnvLxcpaWlGjlypL7zne/oueee0/nz5/Xwww/HakkAAMAyMQuV+++/X2fOnNGCBQsUCAQ0bNgwbdmy5aIbbK81p9OphQsXXvSrJgAAvilsuhY6TDSfEQIAALiG+Fs/AADAWoQKAACwFqECAACs1eVCZdy4cZo9e3aslwEAQEwZY/Too48qPT1dDodDhw4divWSOkWX+GZaAAAQacuWLVq7dq127NihgQMH6vrrr4/1kjoFoQIAQBd08uRJ9enTR7fddlusl9KputyvfqR/f4vtE088ofT0dHm9Xi1atCi8r6amRvfee69SUlLkcrn0gx/8IOKr+hctWqRhw4bplVdeUXZ2tlJSUvTYY4+ptbVVy5cvl9frVWZmpn72s59FvKbD4dCLL76oiRMnKikpSbm5ufL7/Tpx4oTGjRun5ORk3XbbbTp58mTEcW+99ZaGDx+unj17auDAgVq8eLFaWlo69ecDAOjeHnroIc2aNUs1NTVyOBzKyclRW1ubKisrNWDAAPXq1Uu33HKL/vznP4eP2bFjhxwOh9555x3deuut6tWrl8aPH6/6+npt3rxZubm5crlc+uEPf6gvv/zPX3weN26cZs2apdmzZ+u6666Tx+PRSy+9FP6S1tTUVA0aNEibN2+OWONHH32kCRMmKCUlRR6PR9OmTdPnn38e/cmaLmbs2LHG5XKZRYsWmY8//ti8+uqrxuFwmK1bt5rW1lYzbNgwM2bMGPPBBx+YvXv3mhEjRpixY8eGj1+4cKFJSUkxkydPNkeOHDF//etfTWJioikqKjKzZs0yx48fN6+88oqRZPbu3Rs+TpK54YYbzOuvv26qq6vNfffdZ3Jycsz48ePNli1bzNGjR01+fr65++67w8fs2rXLuFwus3btWnPy5EmzdetWk5OTYxYtWnQtf2QAgG6moaHBLFmyxPTr18+cPn3a1NfXm6efftoMHjzYbNmyxZw8edKsWbPGOJ1Os2PHDmOMMe+//76RZPLz883f//53c/DgQTNo0CAzduxYU1hYaA4ePGh27dplMjIyzLJly8KvNXbsWJOammqWLl1qPv74Y7N06VITHx9vJkyYYH7zm9+Yjz/+2MyYMcNkZGSY8+fPG2OM+de//mV69+5tKioqzLFjx8zBgwfNXXfdZe64446oz7VLhsqYMWMixkaNGmXmzZtntm7dauLj401NTU1435EjR4wks3//fmPMv0MlKSnJhEKh8JyioiKTk5NjWltbw2M33XSTqaysDD+WZObPnx9+7Pf7jSTz8ssvh8f++Mc/mp49e4Yf33nnneaZZ56JWOvvf/9706dPnys9fQAAjDHGrFixwvTv398YY0xjY6NJSkoye/bsiZgzffp0M2XKFGPMf0Ll3XffDe+vrKw0kszJkyfDYz/60Y9MUVFR+PFXr7stLS0mOTnZTJs2LTx2+vRpI8n4/X5jjDFLly41hYWFEWupra01kkx1dXVU59kl71EZOnRoxOM+ffqovr5ex44dU1ZWlrKyssL78vLylJaWpmPHjmnUqFGSpJycHKWmpobneDwexcfHKy4uLmKsvr7+a1+3/av+hwwZEjHW2NioUCgkl8ulDz/8ULt37474NVJra6saGxv15ZdfKikp6Wp+DAAASJJOnDihL7/8UnfddVfEeHNzs2699daIsa9ey5KSkjRw4MCIsf3793/tMfHx8crIyLjo+icpfN388MMP9f777yslJeWitZ48eVI33njjZZ9blwyVHj16RDx2OBxqa2u7quMv5zn/e47D4fjasfbjzp07p8WLF2vSpEkXraFnz56XvV4AAP6Xc+fOSZI2bdqkG264IWLfV/9ez1evW9Fe/y513KWuf/fcc49+/vOfX7TWPn36XNY5teuSofJ1cnNzVVtbq9ra2vC7KkePHlVDQ4Py8vKu+XqGDx+u6upqDRo06Jq/NgDgmyMvL09Op1M1NTUaO3ZsrJej4cOH6y9/+YtycnKUkHB1qdGtQqWgoEBDhgzR1KlT9dxzz6mlpUWPPfaYxo4dq5EjR17z9SxYsEATJ05Udna2Jk+erLi4OH344Yf66KOP9PTTT1/z9QAAuqfU1FQ9/vjjmjNnjtra2jRmzBgFg0Ht3r1bLpdLpaWl13Q9ZWVleumllzRlypTwp3RPnDih9evX67e//a3i4+Mv+7m65MeTv47D4dBbb72l6667TrfffrsKCgo0cOBAvf766zFZT1FRkTZu3KitW7dq1KhRys/P14oVK9S/f/+YrAcA0H0tXbpUTz31lCorK5Wbm6u7775bmzZt0oABA675Wvr27avdu3ertbVVhYWFGjJkiGbPnq20tLSI+0Evh8MYYzppnQAAAFelW72jAgAAuhdCBQAAWItQAQAA1iJUAACAtQgVAABgLUIFAABYi1ABAADWIlQAAIC1CBUAAGAtQgUAAFiLUAEAANYiVAAAgLX+D8xllOl0c/CBAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"train = train.drop([\"date_accident\", \"date_consolidation\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:48.553777Z","iopub.execute_input":"2024-03-10T10:45:48.554098Z","iopub.status.idle":"2024-03-10T10:45:48.561338Z","shell.execute_reply.started":"2024-03-10T10:45:48.554071Z","shell.execute_reply":"2024-03-10T10:45:48.560288Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('french')\ntrain['texte'] = train[\"texte\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:48.566020Z","iopub.execute_input":"2024-03-10T10:45:48.566459Z","iopub.status.idle":"2024-03-10T10:45:54.114590Z","shell.execute_reply.started":"2024-03-10T10:45:48.566422Z","shell.execute_reply":"2024-03-10T10:45:54.113670Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# train['sexe'].replace({\"homme\":0,\"femme\":1},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:54.115867Z","iopub.execute_input":"2024-03-10T10:45:54.116494Z","iopub.status.idle":"2024-03-10T10:45:54.121293Z","shell.execute_reply.started":"2024-03-10T10:45:54.116466Z","shell.execute_reply":"2024-03-10T10:45:54.120172Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train = train.drop([\"ID\", \"filename\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:54.122686Z","iopub.execute_input":"2024-03-10T10:45:54.123087Z","iopub.status.idle":"2024-03-10T10:45:54.132186Z","shell.execute_reply.started":"2024-03-10T10:45:54.123048Z","shell.execute_reply":"2024-03-10T10:45:54.131340Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train['text_id'] = np.arange(len(train))\ntest[\"text_id\"] = np.arange(len(test))","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:54.133661Z","iopub.execute_input":"2024-03-10T10:45:54.134058Z","iopub.status.idle":"2024-03-10T10:45:54.143118Z","shell.execute_reply.started":"2024-03-10T10:45:54.134025Z","shell.execute_reply":"2024-03-10T10:45:54.142088Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:54.144332Z","iopub.execute_input":"2024-03-10T10:45:54.144616Z","iopub.status.idle":"2024-03-10T10:45:54.160816Z","shell.execute_reply.started":"2024-03-10T10:45:54.144592Z","shell.execute_reply":"2024-03-10T10:45:54.159838Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"                                                 texte   sexe  text_id\n0    Le : 12/11/2019 Cour d’appel d’Agen chambre so...  homme        0\n1    Le : 12/11/2019 Cour d’appel d’Agen chambre ci...  homme        1\n2    Le : 12/11/2019 Cour d’appel d’Agen Audience p...  femme        2\n3    Le : 12/11/2019 Cour d’appel d’Agen Audience p...  femme        3\n4    Le : 12/11/2019 Cour d’appel d’Agen Audience p...  homme        4\n..                                                 ...    ...      ...\n765  Le : 12/11/2019 Cour d’appel Versailles ct0032...  homme      760\n766  Le : 12/11/2019 Cour d’appel Versailles ct0087...  femme      761\n767  Le : 12/11/2019 Cour d’appel Versailles ct0087...  homme      762\n768  Le : 12/11/2019 Cour d’appel Versailles ct0087...  homme      763\n769  Le : 12/11/2019 Cour d’appel Versailles 5ème c...  homme      764\n\n[765 rows x 3 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>texte</th>\n      <th>sexe</th>\n      <th>text_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Le : 12/11/2019 Cour d’appel d’Agen chambre so...</td>\n      <td>homme</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Le : 12/11/2019 Cour d’appel d’Agen chambre ci...</td>\n      <td>homme</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Le : 12/11/2019 Cour d’appel d’Agen Audience p...</td>\n      <td>femme</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Le : 12/11/2019 Cour d’appel d’Agen Audience p...</td>\n      <td>femme</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Le : 12/11/2019 Cour d’appel d’Agen Audience p...</td>\n      <td>homme</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>765</th>\n      <td>Le : 12/11/2019 Cour d’appel Versailles ct0032...</td>\n      <td>homme</td>\n      <td>760</td>\n    </tr>\n    <tr>\n      <th>766</th>\n      <td>Le : 12/11/2019 Cour d’appel Versailles ct0087...</td>\n      <td>femme</td>\n      <td>761</td>\n    </tr>\n    <tr>\n      <th>767</th>\n      <td>Le : 12/11/2019 Cour d’appel Versailles ct0087...</td>\n      <td>homme</td>\n      <td>762</td>\n    </tr>\n    <tr>\n      <th>768</th>\n      <td>Le : 12/11/2019 Cour d’appel Versailles ct0087...</td>\n      <td>homme</td>\n      <td>763</td>\n    </tr>\n    <tr>\n      <th>769</th>\n      <td>Le : 12/11/2019 Cour d’appel Versailles 5ème c...</td>\n      <td>homme</td>\n      <td>764</td>\n    </tr>\n  </tbody>\n</table>\n<p>765 rows × 3 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# train[\"sexe\"] = train[\"sexe\"].replace({\"homme\":1, \"femme\":0})","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:54.161963Z","iopub.execute_input":"2024-03-10T10:45:54.162343Z","iopub.status.idle":"2024-03-10T10:45:54.168466Z","shell.execute_reply.started":"2024-03-10T10:45:54.162315Z","shell.execute_reply":"2024-03-10T10:45:54.167571Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass JuridiqueDataset_train(Dataset):\n    def __init__(self,\n                 df,\n                 tokenizer,\n                 args\n                ):\n        # args is a dict, a nice way to share the global arguments (even accross multiple files)\n        self.args = args\n        self.tokenizer = tokenizer\n        self.df = df\n        \n    def make_one_item(self,idx):\n        # this function should encode (tokenize) a given text \n        text_id = self.df.iloc[idx].text_id\n        text = self.df.iloc[idx].texte\n        sexe = self.df.iloc[idx].sexe\n        tokenizer_encoding = self.tokenizer(text, max_length=512)\n        outputs = dict(**tokenizer_encoding)\n        \n        outputs['text_id'] = text_id\n        outputs['sexe'] = sexe\n        \n        return outputs\n    \n    def __len__(self) -> int:\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        return self.make_one_item(idx)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:54.169758Z","iopub.execute_input":"2024-03-10T10:45:54.170134Z","iopub.status.idle":"2024-03-10T10:45:54.181188Z","shell.execute_reply.started":"2024-03-10T10:45:54.170101Z","shell.execute_reply":"2024-03-10T10:45:54.180285Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"\nclass JuridiqueDataset_test(Dataset):\n    def __init__(self,\n                 df,\n                 tokenizer,\n                 args\n                ):\n        # args is a dict, a nice way to share the global arguments (even accross multiple files)\n        self.args = args\n        self.tokenizer = tokenizer\n        self.df = df\n        \n    def make_one_item(self,idx):\n        # this function should encode (tokenize) a given text \n        text_id = self.df.iloc[idx].text_id\n        text = self.df.iloc[idx].texte\n        # sexe = self.df.iloc[idx].sexe\n        tokenizer_encoding = self.tokenizer(text, max_length=512)\n        outputs = dict(**tokenizer_encoding)\n        \n        outputs['text_id'] = text_id\n        # outputs['sexe'] = sexe\n        \n        return outputs\n    \n    def __len__(self) -> int:\n        return len(self.df)\n    \n    def __getitem__(self,idx):\n        return self.make_one_item(idx)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:54.182551Z","iopub.execute_input":"2024-03-10T10:45:54.183049Z","iopub.status.idle":"2024-03-10T10:45:54.194689Z","shell.execute_reply.started":"2024-03-10T10:45:54.183015Z","shell.execute_reply":"2024-03-10T10:45:54.193749Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer\n# Apply your dataset module to allocine data with bert-base-uncased tokenizer\n# randomly generate some examples through your dataset (dataset created from AllocineDataset)\nmodel_name = \"almanach/camembert-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:54.195802Z","iopub.execute_input":"2024-03-10T10:45:54.196123Z","iopub.status.idle":"2024-03-10T10:45:56.216878Z","shell.execute_reply.started":"2024-03-10T10:45:54.196091Z","shell.execute_reply":"2024-03-10T10:45:56.215969Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4913ca128821455b8f82575bfaa7ea0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cec634b60b64f76a215620a0c92e8cf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/811k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b93830ab4ebb468887f60edd351839af"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.40M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f9222063ac047d990bccad5079f748a"}},"metadata":{}}]},{"cell_type":"code","source":"import random\nargs = {}\nds = JuridiqueDataset_train(train,tokenizer,args)\nidx = random.choice(range(len(ds)))\n# ds[idx]\n# print(tokenizer.convert_ids_to_tokens(ds[idx]['input_ids']))","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.218420Z","iopub.execute_input":"2024-03-10T10:45:56.218706Z","iopub.status.idle":"2024-03-10T10:45:56.223660Z","shell.execute_reply.started":"2024-03-10T10:45:56.218682Z","shell.execute_reply":"2024-03-10T10:45:56.222469Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"# DataLoader","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.225435Z","iopub.execute_input":"2024-03-10T10:45:56.225779Z","iopub.status.idle":"2024-03-10T10:45:56.379862Z","shell.execute_reply.started":"2024-03-10T10:45:56.225752Z","shell.execute_reply":"2024-03-10T10:45:56.378633Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"## =============================================================================== ##\nclass CustomCollator_train():\n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n\n    def __call__(self, batch):\n        output = dict()\n        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n        output[\"sexe\"] = [sample[\"sexe\"] for sample in batch]\n        output[\"text_id\"] = [sample[\"text_id\"] for sample in batch]\n\n\n        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n\n        # add padding\n        if self.tokenizer.padding_side == \"right\":\n            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n\n        else:\n\n            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n\n        # convert to tensors\n        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n        \n        sexe_to_int = {\"homme\": 0, \"femme\": 1}\n        output[\"sexe\"] = torch.tensor([sexe_to_int[item] for item in output[\"sexe\"]], dtype=torch.long)\n        # output[\"sexe\"] = torch.tensor(output[\"sexe\"], dtype=torch.long)#.unsqueeze(-1) #mettre float au lieu de long\n        output[\"text_id\"] = torch.tensor(output[\"text_id\"], dtype=torch.long)\n        return output\n    \n    ## =============================================================================== ##\nclass CustomCollator_test():\n    def __init__(self, tokenizer):\n        self.tokenizer = tokenizer\n\n    def __call__(self, batch):\n        output = dict()\n        output[\"input_ids\"] = [sample[\"input_ids\"] for sample in batch]\n        output[\"attention_mask\"] = [sample[\"attention_mask\"] for sample in batch]\n        # output[\"sexe\"] = [sample[\"sexe\"] for sample in batch]\n        output[\"text_id\"] = [sample[\"text_id\"] for sample in batch]\n\n\n        batch_max = max([len(ids) for ids in output[\"input_ids\"]])\n\n        # add padding\n        if self.tokenizer.padding_side == \"right\":\n            output[\"input_ids\"] = [s + (batch_max - len(s)) * [self.tokenizer.pad_token_id] for s in output[\"input_ids\"]]\n            output[\"attention_mask\"] = [s + (batch_max - len(s)) * [0] for s in output[\"attention_mask\"]]\n\n        else:\n\n            output[\"input_ids\"] = [(batch_max - len(s)) * [self.tokenizer.pad_token_id] + s for s in output[\"input_ids\"]]\n            output[\"attention_mask\"] = [(batch_max - len(s)) * [0] + s for s in output[\"attention_mask\"]]\n\n        # convert to tensors\n        output[\"input_ids\"] = torch.tensor(output[\"input_ids\"], dtype=torch.long)\n        output[\"attention_mask\"] = torch.tensor(output[\"attention_mask\"], dtype=torch.long)\n        \n        # sexe_to_int = {\"homme\": 0, \"femme\": 1}\n        # output[\"sexe\"] = torch.tensor([sexe_to_int[item] for item in output[\"sexe\"]], dtype=torch.long)\n        # output[\"sexe\"] = torch.tensor(output[\"sexe\"], dtype=torch.long)#.unsqueeze(-1) #mettre float au lieu de long\n        output[\"text_id\"] = torch.tensor(output[\"text_id\"], dtype=torch.long)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.381767Z","iopub.execute_input":"2024-03-10T10:45:56.382133Z","iopub.status.idle":"2024-03-10T10:45:56.402732Z","shell.execute_reply.started":"2024-03-10T10:45:56.382091Z","shell.execute_reply":"2024-03-10T10:45:56.401725Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"collator_function = CustomCollator_train(tokenizer)\nmy_dataset = JuridiqueDataset_train(train,tokenizer,args)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.403892Z","iopub.execute_input":"2024-03-10T10:45:56.404283Z","iopub.status.idle":"2024-03-10T10:45:56.415259Z","shell.execute_reply.started":"2024-03-10T10:45:56.404213Z","shell.execute_reply":"2024-03-10T10:45:56.414259Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"data_loader = DataLoader(my_dataset,drop_last = False,num_workers=0,pin_memory=False,shuffle=False,\n                              batch_size = 2,collate_fn = collator_function)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.416494Z","iopub.execute_input":"2024-03-10T10:45:56.416823Z","iopub.status.idle":"2024-03-10T10:45:56.427387Z","shell.execute_reply.started":"2024-03-10T10:45:56.416787Z","shell.execute_reply":"2024-03-10T10:45:56.426498Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfor batch in tqdm(data_loader):\n    break","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.428469Z","iopub.execute_input":"2024-03-10T10:45:56.428767Z","iopub.status.idle":"2024-03-10T10:45:56.499274Z","shell.execute_reply.started":"2024-03-10T10:45:56.428729Z","shell.execute_reply":"2024-03-10T10:45:56.498349Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"  0%|          | 0/383 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n  0%|          | 0/383 [00:00<?, ?it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"batch['input_ids'].shape,batch['sexe'].shape,batch['attention_mask'].shape","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.500756Z","iopub.execute_input":"2024-03-10T10:45:56.501152Z","iopub.status.idle":"2024-03-10T10:45:56.509659Z","shell.execute_reply.started":"2024-03-10T10:45:56.501119Z","shell.execute_reply":"2024-03-10T10:45:56.508149Z"},"trusted":true},"execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"(torch.Size([2, 512]), torch.Size([2]), torch.Size([2, 512]))"},"metadata":{}}]},{"cell_type":"code","source":"batch['attention_mask']","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.510901Z","iopub.execute_input":"2024-03-10T10:45:56.511894Z","iopub.status.idle":"2024-03-10T10:45:56.541156Z","shell.execute_reply.started":"2024-03-10T10:45:56.511867Z","shell.execute_reply":"2024-03-10T10:45:56.540255Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"tensor([[1, 1, 1,  ..., 1, 1, 1],\n        [1, 1, 1,  ..., 1, 1, 1]])"},"metadata":{}}]},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import AutoConfig, AutoModel\nimport torch.utils.checkpoint\nimport torch.nn.functional as F\n\nclass MyBertModel(nn.Module):\n    def __init__(self, model_name=\"almanach/camembert-base\", num_labels=2):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)        \n        self.backbone = AutoModel.from_pretrained(model_name)\n        self.fc = nn.Linear(self.config.hidden_size, num_labels)\n\n    def forward(self, batch):\n        inputs = {k: v for k, v in batch.items() if k in ['input_ids', 'attention_mask']}\n        outputs = self.backbone(**inputs)\n        x = outputs.last_hidden_state[:, 0, :]\n        x = self.fc(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.542293Z","iopub.execute_input":"2024-03-10T10:45:56.542630Z","iopub.status.idle":"2024-03-10T10:45:56.570575Z","shell.execute_reply.started":"2024-03-10T10:45:56.542605Z","shell.execute_reply":"2024-03-10T10:45:56.569643Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"def train_one_step(batch,model,criterion):\n    \"\"\"\n    Complete this function which should return the loss generate on the bacth data\n    \"\"\"\n    # convert bacth data to same device as model\n    device  = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    batch = batch_to_device(batch,device)\n    # one step forward with the bacth\n    pred = model(batch)\n    \n    # compute loss \n    loss = criterion(pred.squeeze(),batch['sexe'].float().squeeze(-1))\n#     print(loss)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.577277Z","iopub.execute_input":"2024-03-10T10:45:56.577777Z","iopub.status.idle":"2024-03-10T10:45:56.583950Z","shell.execute_reply.started":"2024-03-10T10:45:56.577753Z","shell.execute_reply":"2024-03-10T10:45:56.582810Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"def train_one_epoch(epoch_number,data_loader,model,criterion,optimzer,lr_scheduler):\n    losses = []\n    model.train()\n    start_time = time.time()\n    pbar = tqdm(data_loader)\n    for batch in pbar:\n        loss = train_one_step(batch,model,criterion)\n        pbar.set_postfix({\"loss\":loss.item()})\n        losses.append(loss.item())\n        loss.backward()\n        optimzer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n    \n    lr = scheduler.get_lr()[0]\n    elapsed_time = time.time() - start_time\n    loss_ = np.mean(losses)\n    print(f\"Epoch {epoch_number + 1} :  lr={lr:.6f} t={elapsed_time:.0f}s loss : {loss_:.5f}\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.585238Z","iopub.execute_input":"2024-03-10T10:45:56.585574Z","iopub.status.idle":"2024-03-10T10:45:56.593579Z","shell.execute_reply.started":"2024-03-10T10:45:56.585540Z","shell.execute_reply":"2024-03-10T10:45:56.592663Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"\ndef inference(valid_loader, model):\n    predictions = []\n    model.eval()  # Met le modèle en mode évaluation.\n    \n    device = next(model.parameters()).device\n    \n    with torch.no_grad():\n        for batch in tqdm(valid_loader):\n            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v for k, v in batch.items()}\n            pred = model(batch).sigmoid().squeeze()\n            \n            if pred.dim() == 0:\n                pred = pred.unsqueeze(0)\n            \n            predictions.append(pred.detach().cpu().numpy())\n    \n    predictions = np.concatenate(predictions, axis=0)\n    \n    df_predict = pd.DataFrame({\"sexe_pred\": predictions.tolist()})\n    return df_predict","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.594987Z","iopub.execute_input":"2024-03-10T10:45:56.595346Z","iopub.status.idle":"2024-03-10T10:45:56.606030Z","shell.execute_reply.started":"2024-03-10T10:45:56.595320Z","shell.execute_reply":"2024-03-10T10:45:56.605124Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"def batch_to_device(batch, device):\n    \"\"\"Déplace uniquement les tenseurs du batch vers le dispositif spécifié.\"\"\"\n    batch_dict = {}\n    for key in batch:\n        # Vérifier si l'élément est un tenseur avant de tenter de le déplacer\n        if isinstance(batch[key], torch.Tensor):\n            batch_dict[key] = batch[key].to(device)\n        else:\n            # Si ce n'est pas un tenseur, simplement copier l'élément tel quel\n            batch_dict[key] = batch[key]\n    return batch_dict\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.607250Z","iopub.execute_input":"2024-03-10T10:45:56.607591Z","iopub.status.idle":"2024-03-10T10:45:56.615315Z","shell.execute_reply.started":"2024-03-10T10:45:56.607564Z","shell.execute_reply":"2024-03-10T10:45:56.614289Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Define your model\ndevice = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnet = MyBertModel(model_name=model_name,num_labels=1)\nnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:45:56.616410Z","iopub.execute_input":"2024-03-10T10:45:56.616695Z","iopub.status.idle":"2024-03-10T10:46:04.153346Z","shell.execute_reply.started":"2024-03-10T10:45:56.616663Z","shell.execute_reply":"2024-03-10T10:46:04.152279Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf0dc8d1783f46638387959adef6258f"}},"metadata":{}},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"MyBertModel(\n  (backbone): CamembertModel(\n    (embeddings): CamembertEmbeddings(\n      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): CamembertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x CamembertLayer(\n          (attention): CamembertAttention(\n            (self): CamembertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): CamembertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): CamembertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): CamembertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): CamembertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (fc): Linear(in_features=768, out_features=1, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Define an optimzer \nimport torch.optim as optim\n\noptimizer = optim.AdamW(net.parameters(),lr = 4e-6 )","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:46:04.154857Z","iopub.execute_input":"2024-03-10T10:46:04.155293Z","iopub.status.idle":"2024-03-10T10:46:04.162495Z","shell.execute_reply.started":"2024-03-10T10:46:04.155255Z","shell.execute_reply":"2024-03-10T10:46:04.161504Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"# Define a scheduller for your model training\nfrom transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\n\nBATCH_SIZE = 6\nEPOCHS = 8\nwarmup_steps = 0.04 * (len(train)//BATCH_SIZE)\ntraining_steps = EPOCHS * (len(train)// (BATCH_SIZE))\n\nscheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, training_steps)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:46:04.163759Z","iopub.execute_input":"2024-03-10T10:46:04.164113Z","iopub.status.idle":"2024-03-10T10:46:04.177800Z","shell.execute_reply.started":"2024-03-10T10:46:04.164087Z","shell.execute_reply":"2024-03-10T10:46:04.176964Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"warmup_steps,training_steps","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:46:04.178890Z","iopub.execute_input":"2024-03-10T10:46:04.179186Z","iopub.status.idle":"2024-03-10T10:46:04.185403Z","shell.execute_reply.started":"2024-03-10T10:46:04.179161Z","shell.execute_reply":"2024-03-10T10:46:04.184343Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"(5.08, 1016)"},"metadata":{}}]},{"cell_type":"code","source":"import time\n\ncriterion = nn.BCEWithLogitsLoss().to(device)\nfor epoch_num in range(EPOCHS):\n    net = train_one_epoch(epoch_num,data_loader,net,criterion,optimizer,scheduler)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T10:48:31.556780Z","iopub.execute_input":"2024-03-10T10:48:31.557161Z","iopub.status.idle":"2024-03-10T11:00:18.928466Z","shell.execute_reply.started":"2024-03-10T10:48:31.557133Z","shell.execute_reply":"2024-03-10T11:00:18.927380Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"100%|██████████| 383/383 [01:28<00:00,  4.33it/s, loss=0.324]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1 :  lr=0.000000 t=89s loss : 0.58086\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 383/383 [01:28<00:00,  4.33it/s, loss=0.312]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2 :  lr=0.000001 t=88s loss : 0.58117\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 383/383 [01:28<00:00,  4.35it/s, loss=0.302]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3 :  lr=0.000003 t=88s loss : 0.58070\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 383/383 [01:28<00:00,  4.33it/s, loss=0.164]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4 :  lr=0.000004 t=88s loss : 0.43842\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 383/383 [01:28<00:00,  4.32it/s, loss=0.178]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5 :  lr=0.000002 t=89s loss : 0.29552\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 383/383 [01:28<00:00,  4.33it/s, loss=0.135]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6 :  lr=0.000000 t=88s loss : 0.24307\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 383/383 [01:28<00:00,  4.33it/s, loss=0.131]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7 :  lr=0.000001 t=88s loss : 0.22970\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 383/383 [01:28<00:00,  4.33it/s, loss=0.123]","output_type":"stream"},{"name":"stdout","text":"Epoch 8 :  lr=0.000003 t=88s loss : 0.22800\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"collator_function = CustomCollator_test(tokenizer)\nvalid_dataset = JuridiqueDataset_test(test,tokenizer,args)\nvalid_loader = DataLoader(valid_dataset,drop_last = False,num_workers=0,pin_memory=False,shuffle=False,\n                              batch_size = 6,collate_fn = collator_function)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:02:06.852514Z","iopub.execute_input":"2024-03-10T11:02:06.852901Z","iopub.status.idle":"2024-03-10T11:02:06.858600Z","shell.execute_reply.started":"2024-03-10T11:02:06.852873Z","shell.execute_reply":"2024-03-10T11:02:06.857543Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"pred_df = inference(valid_loader,net)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:02:08.753862Z","iopub.execute_input":"2024-03-10T11:02:08.754955Z","iopub.status.idle":"2024-03-10T11:02:22.093926Z","shell.execute_reply.started":"2024-03-10T11:02:08.754921Z","shell.execute_reply":"2024-03-10T11:02:22.092831Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"100%|██████████| 43/43 [00:13<00:00,  3.23it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TF-IDF","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import f1_score\nfrom sklearn import metrics\nfrom spacy.lang.fr.stop_words import STOP_WORDS as fr_stop\nfrom sklearn.model_selection import train_test_split\nX = train[[\"texte\", 'text_id']]\n\nvect = TfidfVectorizer(\n  max_features=5000,\n  stop_words=list(fr_stop), binary=True)\n\nX = vect.fit_transform(train['texte'])\ntrain[\"sexe\"] = train[\"sexe\"].replace({'homme':0, \"femme\":1})\ny = train['sexe']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = LogisticRegression(random_state=26).fit(X, y)\n\npreds = clf.predict((X_test))\n\nprint(\"f1:\", f1_score(y_test, preds, average='macro'))\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, preds)\nprint(\"AUC: \", metrics.auc(fpr, tpr))","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:02:22.095746Z","iopub.execute_input":"2024-03-10T11:02:22.096073Z","iopub.status.idle":"2024-03-10T11:02:24.221646Z","shell.execute_reply.started":"2024-03-10T11:02:22.096046Z","shell.execute_reply":"2024-03-10T11:02:24.220578Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['neuf', 'qu', 'quelqu'] not in stop_words.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"f1: 0.5647058823529412\nAUC:  0.5795454545454546\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Embedding + fine tuning","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nfrom transformers import AutoConfig, AutoModel\nimport torch.utils.checkpoint\nimport torch.nn.functional as F\n\nclass MyEmbeddingModel(nn.Module):\n    def __init__(self,\n                 model_name=\"flaubert/flaubert_base_uncased\"\n                 ):\n        super().__init__()\n\n        self.config = AutoConfig.from_pretrained(model_name, output_hidden_states=True)        \n        self.backbone = AutoModel.from_pretrained(model_name)\n\n    def forward(self,batch):\n        x = self.backbone(input_ids=batch[\"input_ids\"],attention_mask=batch[\"attention_mask\"]).last_hidden_state\n        # Taking only CLS output for sentence classification\n        x = x[:,0,:]\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:02:24.223031Z","iopub.execute_input":"2024-03-10T11:02:24.223449Z","iopub.status.idle":"2024-03-10T11:02:24.232099Z","shell.execute_reply.started":"2024-03-10T11:02:24.223419Z","shell.execute_reply":"2024-03-10T11:02:24.230888Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"\ndef get_embeddings(model, df):\n    # Assumant que CustomCollator_test, JuridiqueDataset_test, et batch_to_device sont définis ailleurs\n    collator_function = CustomCollator_test(tokenizer)\n    valid_dataset = JuridiqueDataset_test(df, tokenizer, args)  # Remplacez `test` par `df` si `df` est votre DataFrame/variable d'entrée\n    valid_loader = DataLoader(valid_dataset, drop_last=False, num_workers=0, pin_memory=False, shuffle=False,\n                              batch_size=2, collate_fn=collator_function)\n    \n    embed_predictions = []\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    \n    model.eval()\n    with torch.no_grad():  # Désactiver les calculs de gradient pour l'inférence\n        for batch in tqdm(valid_loader):\n            batch = batch_to_device(batch, device)\n            pred = model(batch)\n            # Assurez-vous que pred a toujours 2 dimensions\n            if pred.dim() == 1:\n                pred = pred.unsqueeze(0)\n            pred = pred.detach().cpu().numpy()\n            embed_predictions.append(pred)\n    \n    embeddings = np.concatenate(embed_predictions, axis=0)\n    df_predict = pd.DataFrame(embeddings)  # Vous devrez peut-être ajuster cette ligne en fonction de la structure exacte de vos données\n    \n    return df_predict","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:02:24.234551Z","iopub.execute_input":"2024-03-10T11:02:24.234898Z","iopub.status.idle":"2024-03-10T11:02:24.244631Z","shell.execute_reply.started":"2024-03-10T11:02:24.234869Z","shell.execute_reply":"2024-03-10T11:02:24.243614Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# Define your model\ndevice = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nnet = MyEmbeddingModel(model_name=model_name)\nnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:02:24.245998Z","iopub.execute_input":"2024-03-10T11:02:24.246398Z","iopub.status.idle":"2024-03-10T11:02:24.708114Z","shell.execute_reply.started":"2024-03-10T11:02:24.246367Z","shell.execute_reply":"2024-03-10T11:02:24.707113Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"MyEmbeddingModel(\n  (backbone): CamembertModel(\n    (embeddings): CamembertEmbeddings(\n      (word_embeddings): Embedding(32005, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): CamembertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x CamembertLayer(\n          (attention): CamembertAttention(\n            (self): CamembertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): CamembertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): CamembertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): CamembertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): CamembertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"df_embed_train = get_embeddings(net,train)","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:02:24.709263Z","iopub.execute_input":"2024-03-10T11:02:24.709553Z","iopub.status.idle":"2024-03-10T11:02:57.975538Z","shell.execute_reply.started":"2024-03-10T11:02:24.709529Z","shell.execute_reply":"2024-03-10T11:02:57.974499Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stderr","text":"100%|██████████| 383/383 [00:33<00:00, 11.52it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"df_embed_train","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:02:57.977113Z","iopub.execute_input":"2024-03-10T11:02:57.977562Z","iopub.status.idle":"2024-03-10T11:02:58.011280Z","shell.execute_reply.started":"2024-03-10T11:02:57.977526Z","shell.execute_reply":"2024-03-10T11:02:58.010192Z"},"trusted":true},"execution_count":55,"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5         6    \\\n0   -0.053011  0.166661  0.058750  0.231161 -0.034837  0.057159  0.008483   \n1   -0.066578  0.228916 -0.023085  0.191473 -0.029401  0.016115 -0.034092   \n2   -0.041889  0.157754  0.027409  0.233111 -0.045690  0.016605  0.001600   \n3   -0.007722  0.186229  0.052269  0.220893 -0.021999  0.042606 -0.005421   \n4   -0.054506  0.197065  0.026809  0.193647 -0.020644  0.011269 -0.031566   \n..        ...       ...       ...       ...       ...       ...       ...   \n760  0.017110  0.189999  0.035954  0.196479  0.032863  0.067324 -0.028772   \n761 -0.020720  0.176885  0.066307  0.232115 -0.034848  0.047415 -0.004769   \n762  0.012596  0.232736  0.086343  0.226421 -0.043727  0.050535 -0.007694   \n763 -0.032219  0.216234  0.034283  0.217577 -0.051479 -0.011350 -0.020394   \n764 -0.039096  0.308167  0.043910  0.217966 -0.027468  0.034613  0.000089   \n\n          7         8         9    ...       758       759       760  \\\n0    0.118151 -0.061248  0.045353  ...  0.026767  0.034264 -0.012110   \n1    0.125263 -0.053051  0.069131  ...  0.032451  0.048909 -0.046211   \n2    0.116849 -0.038807  0.056699  ...  0.016943  0.046952  0.005104   \n3    0.120826 -0.031815  0.051929  ...  0.004219  0.057078 -0.061195   \n4    0.140709 -0.014331  0.061200  ...  0.023733 -0.007234  0.004598   \n..        ...       ...       ...  ...       ...       ...       ...   \n760  0.144655  0.019074  0.023254  ... -0.056535 -0.012065 -0.099690   \n761  0.109422 -0.022343  0.042124  ...  0.007435 -0.001697 -0.073582   \n762  0.167672 -0.069338  0.057644  ...  0.034067  0.057129 -0.025944   \n763  0.118757 -0.020196  0.032670  ...  0.019180 -0.013225 -0.021431   \n764  0.173830 -0.062869  0.056817  ...  0.023495  0.012393 -0.032828   \n\n          761       762       763       764       765       766       767  \n0    0.111819  0.039565 -0.028171 -0.154299 -0.168557  0.073480 -0.022342  \n1    0.107168  0.019107 -0.017993 -0.159349 -0.167348  0.118990 -0.034464  \n2    0.114351  0.039171 -0.049124 -0.205128 -0.188495  0.085562 -0.041652  \n3    0.127011  0.066782 -0.010784 -0.160560 -0.176241  0.135467 -0.008193  \n4    0.138585  0.046910 -0.024320 -0.171208 -0.147630  0.115746 -0.040100  \n..        ...       ...       ...       ...       ...       ...       ...  \n760  0.156556 -0.027059 -0.009490 -0.106916 -0.168025  0.104594 -0.018467  \n761  0.137719  0.047119 -0.018860 -0.161260 -0.147326  0.088928 -0.028378  \n762  0.111654 -0.011729  0.004388 -0.148219 -0.153721  0.116613 -0.043920  \n763  0.144113  0.042651  0.005780 -0.171688 -0.174505  0.139839 -0.048927  \n764  0.139098  0.063382  0.004418 -0.130653 -0.150457  0.098749 -0.063862  \n\n[765 rows x 768 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>758</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-0.053011</td>\n      <td>0.166661</td>\n      <td>0.058750</td>\n      <td>0.231161</td>\n      <td>-0.034837</td>\n      <td>0.057159</td>\n      <td>0.008483</td>\n      <td>0.118151</td>\n      <td>-0.061248</td>\n      <td>0.045353</td>\n      <td>...</td>\n      <td>0.026767</td>\n      <td>0.034264</td>\n      <td>-0.012110</td>\n      <td>0.111819</td>\n      <td>0.039565</td>\n      <td>-0.028171</td>\n      <td>-0.154299</td>\n      <td>-0.168557</td>\n      <td>0.073480</td>\n      <td>-0.022342</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.066578</td>\n      <td>0.228916</td>\n      <td>-0.023085</td>\n      <td>0.191473</td>\n      <td>-0.029401</td>\n      <td>0.016115</td>\n      <td>-0.034092</td>\n      <td>0.125263</td>\n      <td>-0.053051</td>\n      <td>0.069131</td>\n      <td>...</td>\n      <td>0.032451</td>\n      <td>0.048909</td>\n      <td>-0.046211</td>\n      <td>0.107168</td>\n      <td>0.019107</td>\n      <td>-0.017993</td>\n      <td>-0.159349</td>\n      <td>-0.167348</td>\n      <td>0.118990</td>\n      <td>-0.034464</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.041889</td>\n      <td>0.157754</td>\n      <td>0.027409</td>\n      <td>0.233111</td>\n      <td>-0.045690</td>\n      <td>0.016605</td>\n      <td>0.001600</td>\n      <td>0.116849</td>\n      <td>-0.038807</td>\n      <td>0.056699</td>\n      <td>...</td>\n      <td>0.016943</td>\n      <td>0.046952</td>\n      <td>0.005104</td>\n      <td>0.114351</td>\n      <td>0.039171</td>\n      <td>-0.049124</td>\n      <td>-0.205128</td>\n      <td>-0.188495</td>\n      <td>0.085562</td>\n      <td>-0.041652</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.007722</td>\n      <td>0.186229</td>\n      <td>0.052269</td>\n      <td>0.220893</td>\n      <td>-0.021999</td>\n      <td>0.042606</td>\n      <td>-0.005421</td>\n      <td>0.120826</td>\n      <td>-0.031815</td>\n      <td>0.051929</td>\n      <td>...</td>\n      <td>0.004219</td>\n      <td>0.057078</td>\n      <td>-0.061195</td>\n      <td>0.127011</td>\n      <td>0.066782</td>\n      <td>-0.010784</td>\n      <td>-0.160560</td>\n      <td>-0.176241</td>\n      <td>0.135467</td>\n      <td>-0.008193</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.054506</td>\n      <td>0.197065</td>\n      <td>0.026809</td>\n      <td>0.193647</td>\n      <td>-0.020644</td>\n      <td>0.011269</td>\n      <td>-0.031566</td>\n      <td>0.140709</td>\n      <td>-0.014331</td>\n      <td>0.061200</td>\n      <td>...</td>\n      <td>0.023733</td>\n      <td>-0.007234</td>\n      <td>0.004598</td>\n      <td>0.138585</td>\n      <td>0.046910</td>\n      <td>-0.024320</td>\n      <td>-0.171208</td>\n      <td>-0.147630</td>\n      <td>0.115746</td>\n      <td>-0.040100</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>760</th>\n      <td>0.017110</td>\n      <td>0.189999</td>\n      <td>0.035954</td>\n      <td>0.196479</td>\n      <td>0.032863</td>\n      <td>0.067324</td>\n      <td>-0.028772</td>\n      <td>0.144655</td>\n      <td>0.019074</td>\n      <td>0.023254</td>\n      <td>...</td>\n      <td>-0.056535</td>\n      <td>-0.012065</td>\n      <td>-0.099690</td>\n      <td>0.156556</td>\n      <td>-0.027059</td>\n      <td>-0.009490</td>\n      <td>-0.106916</td>\n      <td>-0.168025</td>\n      <td>0.104594</td>\n      <td>-0.018467</td>\n    </tr>\n    <tr>\n      <th>761</th>\n      <td>-0.020720</td>\n      <td>0.176885</td>\n      <td>0.066307</td>\n      <td>0.232115</td>\n      <td>-0.034848</td>\n      <td>0.047415</td>\n      <td>-0.004769</td>\n      <td>0.109422</td>\n      <td>-0.022343</td>\n      <td>0.042124</td>\n      <td>...</td>\n      <td>0.007435</td>\n      <td>-0.001697</td>\n      <td>-0.073582</td>\n      <td>0.137719</td>\n      <td>0.047119</td>\n      <td>-0.018860</td>\n      <td>-0.161260</td>\n      <td>-0.147326</td>\n      <td>0.088928</td>\n      <td>-0.028378</td>\n    </tr>\n    <tr>\n      <th>762</th>\n      <td>0.012596</td>\n      <td>0.232736</td>\n      <td>0.086343</td>\n      <td>0.226421</td>\n      <td>-0.043727</td>\n      <td>0.050535</td>\n      <td>-0.007694</td>\n      <td>0.167672</td>\n      <td>-0.069338</td>\n      <td>0.057644</td>\n      <td>...</td>\n      <td>0.034067</td>\n      <td>0.057129</td>\n      <td>-0.025944</td>\n      <td>0.111654</td>\n      <td>-0.011729</td>\n      <td>0.004388</td>\n      <td>-0.148219</td>\n      <td>-0.153721</td>\n      <td>0.116613</td>\n      <td>-0.043920</td>\n    </tr>\n    <tr>\n      <th>763</th>\n      <td>-0.032219</td>\n      <td>0.216234</td>\n      <td>0.034283</td>\n      <td>0.217577</td>\n      <td>-0.051479</td>\n      <td>-0.011350</td>\n      <td>-0.020394</td>\n      <td>0.118757</td>\n      <td>-0.020196</td>\n      <td>0.032670</td>\n      <td>...</td>\n      <td>0.019180</td>\n      <td>-0.013225</td>\n      <td>-0.021431</td>\n      <td>0.144113</td>\n      <td>0.042651</td>\n      <td>0.005780</td>\n      <td>-0.171688</td>\n      <td>-0.174505</td>\n      <td>0.139839</td>\n      <td>-0.048927</td>\n    </tr>\n    <tr>\n      <th>764</th>\n      <td>-0.039096</td>\n      <td>0.308167</td>\n      <td>0.043910</td>\n      <td>0.217966</td>\n      <td>-0.027468</td>\n      <td>0.034613</td>\n      <td>0.000089</td>\n      <td>0.173830</td>\n      <td>-0.062869</td>\n      <td>0.056817</td>\n      <td>...</td>\n      <td>0.023495</td>\n      <td>0.012393</td>\n      <td>-0.032828</td>\n      <td>0.139098</td>\n      <td>0.063382</td>\n      <td>0.004418</td>\n      <td>-0.130653</td>\n      <td>-0.150457</td>\n      <td>0.098749</td>\n      <td>-0.063862</td>\n    </tr>\n  </tbody>\n</table>\n<p>765 rows × 768 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"X=df_embed_train\n\n# y=train['sexe']\n# train[\"sexe\"].replace({\"homme\":0, \"femme\":1}, inplace=True)\ny = train['sexe']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nclf = LogisticRegression(random_state=26).fit(X, y)\n\npreds= clf.predict(X_test)\n\nfpr, tpr, thresholds = metrics.roc_curve(y_test, preds)\nprint(\"AUC: \",metrics.auc(fpr, tpr))\n\nprint(\"F1: \", f1_score(y_test, preds, average='macro'))\n# print(f1_score(y_test, (pred_df[\"sexe_pred\"].values>0.5)*1, average='macro'))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:23:23.448468Z","iopub.execute_input":"2024-03-10T11:23:23.448889Z","iopub.status.idle":"2024-03-10T11:23:23.675981Z","shell.execute_reply.started":"2024-03-10T11:23:23.448861Z","shell.execute_reply":"2024-03-10T11:23:23.674646Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"AUC:  0.5635946622185154\nF1:  0.5411764705882353\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\nSTOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n\nIncrease the number of iterations (max_iter) or scale the data as shown in:\n    https://scikit-learn.org/stable/modules/preprocessing.html\nPlease also refer to the documentation for alternative solver options:\n    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n  n_iter_i = _check_optimize_result(\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:24:06.753485Z","iopub.execute_input":"2024-03-10T11:24:06.754372Z","iopub.status.idle":"2024-03-10T11:24:06.786947Z","shell.execute_reply.started":"2024-03-10T11:24:06.754335Z","shell.execute_reply":"2024-03-10T11:24:06.785817Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"          0         1         2         3         4         5         6    \\\n357  0.008450  0.175297  0.006828  0.222527 -0.022800  0.038912 -0.011014   \n259 -0.041648  0.267954  0.050232  0.171575 -0.014504  0.035172 -0.011602   \n751 -0.079703  0.211683  0.006514  0.241371  0.014056 -0.004454 -0.040448   \n193  0.023601  0.192810  0.043783  0.146961 -0.026103  0.076152  0.000844   \n333 -0.037775  0.251438  0.029225  0.191056 -0.023232  0.046038 -0.016886   \n..        ...       ...       ...       ...       ...       ...       ...   \n60   0.003810  0.189897  0.058585  0.207873 -0.014953  0.060155 -0.037539   \n552 -0.035122  0.246322  0.034985  0.215352 -0.026714  0.048496 -0.003085   \n342 -0.017299  0.249349  0.052211  0.176504 -0.006724  0.042166 -0.042370   \n324 -0.026264  0.226714  0.020922  0.180880 -0.027077  0.028272 -0.000024   \n244 -0.029395  0.268957  0.043672  0.184377 -0.032014  0.036855 -0.001535   \n\n          7         8         9    ...       758       759       760  \\\n357  0.136758 -0.069220  0.055646  ... -0.019995  0.049186 -0.067075   \n259  0.123324 -0.019201  0.099488  ... -0.009551 -0.006824 -0.061646   \n751  0.141731 -0.017457  0.043284  ...  0.025158 -0.006539 -0.016201   \n193  0.161031 -0.024403  0.024968  ... -0.009488 -0.056921 -0.127872   \n333  0.124778 -0.016784  0.088705  ...  0.006154 -0.013823 -0.042597   \n..        ...       ...       ...  ...       ...       ...       ...   \n60   0.156913 -0.043152  0.040623  ... -0.031721 -0.003887 -0.090510   \n552  0.112471 -0.022087  0.050283  ... -0.011738  0.005508 -0.023086   \n342  0.122073 -0.050621  0.107918  ...  0.011801  0.029157 -0.054775   \n324  0.124348 -0.042778  0.089742  ...  0.011147 -0.008633 -0.022951   \n244  0.124186 -0.008344  0.062724  ...  0.017921  0.001285 -0.051890   \n\n          761       762       763       764       765       766       767  \n357  0.104231  0.052251  0.037107 -0.147169 -0.154660  0.083329 -0.038886  \n259  0.134376  0.011433  0.018874 -0.144061 -0.158923  0.138762 -0.051799  \n751  0.131315 -0.006621 -0.037080 -0.123813 -0.125377  0.084792 -0.044691  \n193  0.108799  0.090147  0.051756 -0.131189 -0.141939  0.137297  0.000827  \n333  0.128750  0.016591  0.003557 -0.158984 -0.149552  0.123487 -0.029078  \n..        ...       ...       ...       ...       ...       ...       ...  \n60   0.131012  0.040185  0.011249 -0.138993 -0.160630  0.153034 -0.035965  \n552  0.142254  0.005178 -0.000947 -0.122173 -0.163761  0.095888 -0.048094  \n342  0.139739  0.044497  0.000900 -0.142780 -0.176885  0.145285 -0.017183  \n324  0.146232  0.050360  0.017688 -0.149096 -0.169513  0.145050 -0.031312  \n244  0.147769  0.037110  0.009961 -0.140404 -0.155041  0.135703 -0.071340  \n\n[153 rows x 768 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>758</th>\n      <th>759</th>\n      <th>760</th>\n      <th>761</th>\n      <th>762</th>\n      <th>763</th>\n      <th>764</th>\n      <th>765</th>\n      <th>766</th>\n      <th>767</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>357</th>\n      <td>0.008450</td>\n      <td>0.175297</td>\n      <td>0.006828</td>\n      <td>0.222527</td>\n      <td>-0.022800</td>\n      <td>0.038912</td>\n      <td>-0.011014</td>\n      <td>0.136758</td>\n      <td>-0.069220</td>\n      <td>0.055646</td>\n      <td>...</td>\n      <td>-0.019995</td>\n      <td>0.049186</td>\n      <td>-0.067075</td>\n      <td>0.104231</td>\n      <td>0.052251</td>\n      <td>0.037107</td>\n      <td>-0.147169</td>\n      <td>-0.154660</td>\n      <td>0.083329</td>\n      <td>-0.038886</td>\n    </tr>\n    <tr>\n      <th>259</th>\n      <td>-0.041648</td>\n      <td>0.267954</td>\n      <td>0.050232</td>\n      <td>0.171575</td>\n      <td>-0.014504</td>\n      <td>0.035172</td>\n      <td>-0.011602</td>\n      <td>0.123324</td>\n      <td>-0.019201</td>\n      <td>0.099488</td>\n      <td>...</td>\n      <td>-0.009551</td>\n      <td>-0.006824</td>\n      <td>-0.061646</td>\n      <td>0.134376</td>\n      <td>0.011433</td>\n      <td>0.018874</td>\n      <td>-0.144061</td>\n      <td>-0.158923</td>\n      <td>0.138762</td>\n      <td>-0.051799</td>\n    </tr>\n    <tr>\n      <th>751</th>\n      <td>-0.079703</td>\n      <td>0.211683</td>\n      <td>0.006514</td>\n      <td>0.241371</td>\n      <td>0.014056</td>\n      <td>-0.004454</td>\n      <td>-0.040448</td>\n      <td>0.141731</td>\n      <td>-0.017457</td>\n      <td>0.043284</td>\n      <td>...</td>\n      <td>0.025158</td>\n      <td>-0.006539</td>\n      <td>-0.016201</td>\n      <td>0.131315</td>\n      <td>-0.006621</td>\n      <td>-0.037080</td>\n      <td>-0.123813</td>\n      <td>-0.125377</td>\n      <td>0.084792</td>\n      <td>-0.044691</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>0.023601</td>\n      <td>0.192810</td>\n      <td>0.043783</td>\n      <td>0.146961</td>\n      <td>-0.026103</td>\n      <td>0.076152</td>\n      <td>0.000844</td>\n      <td>0.161031</td>\n      <td>-0.024403</td>\n      <td>0.024968</td>\n      <td>...</td>\n      <td>-0.009488</td>\n      <td>-0.056921</td>\n      <td>-0.127872</td>\n      <td>0.108799</td>\n      <td>0.090147</td>\n      <td>0.051756</td>\n      <td>-0.131189</td>\n      <td>-0.141939</td>\n      <td>0.137297</td>\n      <td>0.000827</td>\n    </tr>\n    <tr>\n      <th>333</th>\n      <td>-0.037775</td>\n      <td>0.251438</td>\n      <td>0.029225</td>\n      <td>0.191056</td>\n      <td>-0.023232</td>\n      <td>0.046038</td>\n      <td>-0.016886</td>\n      <td>0.124778</td>\n      <td>-0.016784</td>\n      <td>0.088705</td>\n      <td>...</td>\n      <td>0.006154</td>\n      <td>-0.013823</td>\n      <td>-0.042597</td>\n      <td>0.128750</td>\n      <td>0.016591</td>\n      <td>0.003557</td>\n      <td>-0.158984</td>\n      <td>-0.149552</td>\n      <td>0.123487</td>\n      <td>-0.029078</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>0.003810</td>\n      <td>0.189897</td>\n      <td>0.058585</td>\n      <td>0.207873</td>\n      <td>-0.014953</td>\n      <td>0.060155</td>\n      <td>-0.037539</td>\n      <td>0.156913</td>\n      <td>-0.043152</td>\n      <td>0.040623</td>\n      <td>...</td>\n      <td>-0.031721</td>\n      <td>-0.003887</td>\n      <td>-0.090510</td>\n      <td>0.131012</td>\n      <td>0.040185</td>\n      <td>0.011249</td>\n      <td>-0.138993</td>\n      <td>-0.160630</td>\n      <td>0.153034</td>\n      <td>-0.035965</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>-0.035122</td>\n      <td>0.246322</td>\n      <td>0.034985</td>\n      <td>0.215352</td>\n      <td>-0.026714</td>\n      <td>0.048496</td>\n      <td>-0.003085</td>\n      <td>0.112471</td>\n      <td>-0.022087</td>\n      <td>0.050283</td>\n      <td>...</td>\n      <td>-0.011738</td>\n      <td>0.005508</td>\n      <td>-0.023086</td>\n      <td>0.142254</td>\n      <td>0.005178</td>\n      <td>-0.000947</td>\n      <td>-0.122173</td>\n      <td>-0.163761</td>\n      <td>0.095888</td>\n      <td>-0.048094</td>\n    </tr>\n    <tr>\n      <th>342</th>\n      <td>-0.017299</td>\n      <td>0.249349</td>\n      <td>0.052211</td>\n      <td>0.176504</td>\n      <td>-0.006724</td>\n      <td>0.042166</td>\n      <td>-0.042370</td>\n      <td>0.122073</td>\n      <td>-0.050621</td>\n      <td>0.107918</td>\n      <td>...</td>\n      <td>0.011801</td>\n      <td>0.029157</td>\n      <td>-0.054775</td>\n      <td>0.139739</td>\n      <td>0.044497</td>\n      <td>0.000900</td>\n      <td>-0.142780</td>\n      <td>-0.176885</td>\n      <td>0.145285</td>\n      <td>-0.017183</td>\n    </tr>\n    <tr>\n      <th>324</th>\n      <td>-0.026264</td>\n      <td>0.226714</td>\n      <td>0.020922</td>\n      <td>0.180880</td>\n      <td>-0.027077</td>\n      <td>0.028272</td>\n      <td>-0.000024</td>\n      <td>0.124348</td>\n      <td>-0.042778</td>\n      <td>0.089742</td>\n      <td>...</td>\n      <td>0.011147</td>\n      <td>-0.008633</td>\n      <td>-0.022951</td>\n      <td>0.146232</td>\n      <td>0.050360</td>\n      <td>0.017688</td>\n      <td>-0.149096</td>\n      <td>-0.169513</td>\n      <td>0.145050</td>\n      <td>-0.031312</td>\n    </tr>\n    <tr>\n      <th>244</th>\n      <td>-0.029395</td>\n      <td>0.268957</td>\n      <td>0.043672</td>\n      <td>0.184377</td>\n      <td>-0.032014</td>\n      <td>0.036855</td>\n      <td>-0.001535</td>\n      <td>0.124186</td>\n      <td>-0.008344</td>\n      <td>0.062724</td>\n      <td>...</td>\n      <td>0.017921</td>\n      <td>0.001285</td>\n      <td>-0.051890</td>\n      <td>0.147769</td>\n      <td>0.037110</td>\n      <td>0.009961</td>\n      <td>-0.140404</td>\n      <td>-0.155041</td>\n      <td>0.135703</td>\n      <td>-0.071340</td>\n    </tr>\n  </tbody>\n</table>\n<p>153 rows × 768 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2024-03-10T11:23:57.509733Z","iopub.execute_input":"2024-03-10T11:23:57.510132Z","iopub.status.idle":"2024-03-10T11:23:57.517430Z","shell.execute_reply.started":"2024-03-10T11:23:57.510102Z","shell.execute_reply":"2024-03-10T11:23:57.516205Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}